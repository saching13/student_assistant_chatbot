{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3oxVq6vQ76r7",
    "pycharm": {}
   },
   "source": [
    "# Building a Conversational Chatbot for Slack using Rasa and Python -Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kIFYA-Kp8aK4",
    "pycharm": {}
   },
   "source": [
    "## Starting Jupyter Notebook with necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R0_7gOmu0r3v",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import logging, io, json, warnings\n",
    "logging.basicConfig(level=\"INFO\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IVAF41hr8jU5",
    "pycharm": {}
   },
   "source": [
    "# Installations\n",
    "* Rasa NLU\n",
    "* Rasa Core\n",
    "* SpaCy Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4049
    },
    "colab_type": "code",
    "id": "UsvAOHF_1dAY",
    "outputId": "f65c2c83-e7ae-46ef-e800-e43dcb854766",
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rasa_core==0.9.6\n",
      "  Using cached https://files.pythonhosted.org/packages/72/de/82e762685a991351a9f89d934b1b25fe04d10462cf4017f93227cb4d9058/rasa_core-0.9.6-py2.py3-none-any.whl\n",
      "Collecting rasa_nlu[spacy]\n",
      "  Using cached https://files.pythonhosted.org/packages/d6/53/31b6b14e124fa916c10e8e58d650cff57ace0027a9e69a0788b1afcc26f4/rasa_nlu-0.14.6-py2.py3-none-any.whl\n",
      "Collecting python-telegram-bot~=10.0 (from rasa_core==0.9.6)\n",
      "  Using cached https://files.pythonhosted.org/packages/f1/51/d1bd383522c12b313eddd7b97b8e7d6cd2a8e3b44b8ff3c88e4a7b045cc8/python_telegram_bot-10.1.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: coloredlogs~=10.0 in /usr/local/lib/python3.6/site-packages (from rasa_core==0.9.6) (10.0)\n",
      "Requirement already satisfied, skipping upgrade: ConfigArgParse~=0.13.0 in /usr/local/lib/python3.6/site-packages (from rasa_core==0.9.6) (0.13.0)\n",
      "Requirement already satisfied, skipping upgrade: graphviz~=0.8.0 in /usr/local/lib/python3.6/site-packages (from rasa_core==0.9.6) (0.8.4)\n",
      "Requirement already satisfied, skipping upgrade: requests~=2.15 in /usr/local/lib/python3.6/site-packages (from rasa_core==0.9.6) (2.21.0)\n",
      "Requirement already satisfied, skipping upgrade: mattermostwrapper~=2.0 in /usr/local/lib/python3.6/site-packages (from rasa_core==0.9.6) (2.1)\n",
      "Requirement already satisfied, skipping upgrade: fbmessenger~=5.0 in /usr/local/lib/python3.6/site-packages (from rasa_core==0.9.6) (5.4.0)\n",
      "Requirement already satisfied, skipping upgrade: flask-cors~=3.0 in /usr/local/lib/python3.6/site-packages (from rasa_core==0.9.6) (3.0.7)\n",
      "Requirement already satisfied, skipping upgrade: ruamel.yaml~=0.15.0 in /usr/local/lib/python3.6/site-packages (from rasa_core==0.9.6) (0.15.89)\n",
      "Collecting tensorflow<1.9,>=1.7 (from rasa_core==0.9.6)\n",
      "  Using cached https://files.pythonhosted.org/packages/03/ad/d732a5d9d50bfcd8aeb6e4a266065a8868829388e4e2b529ff689f1fc923/tensorflow-1.8.0-cp36-cp36m-macosx_10_11_x86_64.whl\n",
      "^C\n",
      "\u001b[31mOperation cancelled by user\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "python = sys.executable\n",
    "\n",
    "# In your environment run:\n",
    "!{python} -m pip install -U rasa_core==0.9.6 rasa_nlu[spacy];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "wyCva14-1gD4",
    "outputId": "642d04c1-b9ad-4ed0-fb28-ee9bef21507b",
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_md==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.0.0/en_core_web_md-2.0.0.tar.gz#egg=en_core_web_md==2.0.0 in /usr/local/lib/python3.6/site-packages (2.0.0)\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /usr/local/lib/python3.6/site-packages/en_core_web_md -->\n",
      "    /usr/local/lib/python3.6/site-packages/spacy/data/en_core_web_md\n",
      "\n",
      "    You can now load the model via spacy.load('en_core_web_md')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!{python} -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v7JQlbqR9CHC",
    "pycharm": {}
   },
   "source": [
    "## Downloading the English Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "eRmnEdML3OhH",
    "outputId": "cb852307-d652-40c3-cf3d-66c54f833908",
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[93m    Linking successful\u001b[0m\r\n",
      "    /usr/local/lib/python3.6/site-packages/en_core_web_md -->\r\n",
      "    /usr/local/lib/python3.6/site-packages/spacy/data/en\r\n",
      "\r\n",
      "    You can now load the model via spacy.load('en')\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!{python} -m spacy link en_core_web_md en --force;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rasa_core in /usr/local/lib/python3.6/site-packages (0.13.3)\n",
      "Requirement already satisfied: keras-applications==1.0.6 in /usr/local/lib/python3.6/site-packages (from rasa_core) (1.0.6)\n",
      "Requirement already satisfied: flask-cors~=3.0 in /usr/local/lib/python3.6/site-packages (from rasa_core) (3.0.7)\n",
      "Requirement already satisfied: slackclient~=1.0 in /usr/local/lib/python3.6/site-packages (from rasa_core) (1.3.1)\n",
      "Requirement already satisfied: coloredlogs~=10.0 in /usr/local/lib/python3.6/site-packages (from rasa_core) (10.0)\n",
      "Requirement already satisfied: requests~=2.20 in /usr/local/lib/python3.6/site-packages (from rasa_core) (2.21.0)\n",
      "Requirement already satisfied: fbmessenger~=5.0 in /usr/local/lib/python3.6/site-packages (from rasa_core) (5.4.0)\n",
      "Requirement already satisfied: rasa-nlu~=0.14.0 in /usr/local/lib/python3.6/site-packages (from rasa_core) (0.14.4)\n",
      "Requirement already satisfied: tqdm~=4.0 in /usr/local/lib/python3.6/site-packages (from rasa_core) (4.31.1)\n",
      "Requirement already satisfied: packaging~=18.0 in /usr/local/lib/python3.6/site-packages (from rasa_core) (18.0)\n",
      "Requirement already satisfied: rocketchat-API~=0.6.0 in /usr/local/lib/python3.6/site-packages (from rasa_core) (0.6.27)\n",
      "Requirement already satisfied: twilio~=6.0 in /usr/local/lib/python3.6/site-packages (from rasa_core) (6.25.1)\n",
      "Requirement already satisfied: webexteamssdk~=1.0 in /usr/local/lib/python3.6/site-packages (from rasa_core) (1.1.1)\n",
      "Requirement already satisfied: ruamel.yaml~=0.15.0 in /usr/local/lib/python3.6/site-packages (from rasa_core) (0.15.89)\n",
      "Requirement already satisfied: gevent~=1.4 in /usr/local/lib/python3.6/site-packages (from rasa_core) (1.4.0)\n",
      "Requirement already satisfied: python-telegram-bot~=11.0 in /usr/local/lib/python3.6/site-packages (from rasa_core) (11.1.0)\n",
      "Requirement already satisfied: mattermostwrapper~=2.0 in /usr/local/lib/python3.6/site-packages (from rasa_core) (2.1)\n",
      "Requirement already satisfied: rasa-core-sdk~=0.12.1 in /usr/local/lib/python3.6/site-packages (from rasa_core) (0.12.2)\n",
      "Requirement already satisfied: pymongo~=3.7 in /usr/local/lib/python3.6/site-packages (from rasa_core) (3.7.2)\n",
      "Requirement already satisfied: jsonschema~=2.6 in /usr/local/lib/python3.6/site-packages (from rasa_core) (2.6.0)\n",
      "Requirement already satisfied: questionary>=1.0.1 in /usr/local/lib/python3.6/site-packages (from rasa_core) (1.0.2)\n",
      "Requirement already satisfied: tensorflow~=1.12.0 in /usr/local/lib/python3.6/site-packages (from rasa_core) (1.12.0)\n",
      "Requirement already satisfied: scipy~=1.2 in /usr/local/lib/python3.6/site-packages (from rasa_core) (1.2.1)\n",
      "Requirement already satisfied: apscheduler~=3.0 in /usr/local/lib/python3.6/site-packages (from rasa_core) (3.5.3)\n",
      "Requirement already satisfied: pydot~=1.4 in /usr/local/lib/python3.6/site-packages (from rasa_core) (1.4.1)\n",
      "Requirement already satisfied: redis~=2.0 in /usr/local/lib/python3.6/site-packages (from rasa_core) (2.10.6)\n",
      "Requirement already satisfied: typing~=3.0 in /usr/local/lib/python3.6/site-packages (from rasa_core) (3.6.6)\n",
      "Requirement already satisfied: pykwalify~=1.7.0 in /usr/local/lib/python3.6/site-packages (from rasa_core) (1.7.0)\n",
      "Requirement already satisfied: python-socketio~=3.0 in /usr/local/lib/python3.6/site-packages (from rasa_core) (3.1.2)\n",
      "Requirement already satisfied: flask-jwt-simple~=0.0.3 in /usr/local/lib/python3.6/site-packages (from rasa_core) (0.0.3)\n",
      "Requirement already satisfied: scikit-learn~=0.20.0 in /usr/local/lib/python3.6/site-packages (from rasa_core) (0.20.3)\n",
      "Requirement already satisfied: pytz~=2018.9 in /usr/local/lib/python3.6/site-packages (from rasa_core) (2018.9)\n",
      "Requirement already satisfied: jsonpickle~=1.0 in /usr/local/lib/python3.6/site-packages (from rasa_core) (1.1)\n",
      "Requirement already satisfied: python-dateutil~=2.7 in /usr/local/lib/python3.6/site-packages (from rasa_core) (2.7.5)\n",
      "Requirement already satisfied: flask~=1.0 in /usr/local/lib/python3.6/site-packages (from rasa_core) (1.0.2)\n",
      "Requirement already satisfied: colorclass~=2.2 in /usr/local/lib/python3.6/site-packages (from rasa_core) (2.2.0)\n",
      "Requirement already satisfied: networkx~=2.2 in /usr/local/lib/python3.6/site-packages (from rasa_core) (2.2)\n",
      "Requirement already satisfied: terminaltables~=3.1 in /usr/local/lib/python3.6/site-packages (from rasa_core) (3.1.0)\n",
      "Requirement already satisfied: fakeredis~=0.10.0 in /usr/local/lib/python3.6/site-packages (from rasa_core) (0.10.3)\n",
      "Requirement already satisfied: numpy~=1.16 in /usr/local/lib/python3.6/site-packages (from rasa_core) (1.16.2)\n",
      "Requirement already satisfied: keras-preprocessing==1.0.5 in /usr/local/lib/python3.6/site-packages (from rasa_core) (1.0.5)\n",
      "Requirement already satisfied: colorhash~=1.0 in /usr/local/lib/python3.6/site-packages (from rasa_core) (1.0.2)\n",
      "Requirement already satisfied: pika~=0.12.0 in /usr/local/lib/python3.6/site-packages (from rasa_core) (0.12.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/site-packages (from keras-applications==1.0.6->rasa_core) (2.8.0)\n",
      "Requirement already satisfied: Six in /usr/local/lib/python3.6/site-packages (from flask-cors~=3.0->rasa_core) (1.11.0)\n",
      "Requirement already satisfied: websocket-client<0.55.0,>=0.35 in /usr/local/lib/python3.6/site-packages (from slackclient~=1.0->rasa_core) (0.54.0)\n",
      "Requirement already satisfied: humanfriendly>=4.7 in /usr/local/lib/python3.6/site-packages (from coloredlogs~=10.0->rasa_core) (4.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/site-packages (from requests~=2.20->rasa_core) (2018.11.29)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/site-packages (from requests~=2.20->rasa_core) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/site-packages (from requests~=2.20->rasa_core) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/site-packages (from requests~=2.20->rasa_core) (1.24.1)\n",
      "Requirement already satisfied: matplotlib~=2.0 in /usr/local/lib/python3.6/site-packages (from rasa-nlu~=0.14.0->rasa_core) (2.2.4)\n",
      "Requirement already satisfied: cloudpickle~=0.6.1 in /usr/local/lib/python3.6/site-packages (from rasa-nlu~=0.14.0->rasa_core) (0.6.1)\n",
      "Requirement already satisfied: boto3~=1.5 in /usr/local/lib/python3.6/site-packages (from rasa-nlu~=0.14.0->rasa_core) (1.9.113)\n",
      "Requirement already satisfied: simplejson~=3.13 in /usr/local/lib/python3.6/site-packages (from rasa-nlu~=0.14.0->rasa_core) (3.16.0)\n",
      "Requirement already satisfied: klein~=17.10 in /usr/local/lib/python3.6/site-packages (from rasa-nlu~=0.14.0->rasa_core) (17.10.0)\n",
      "Requirement already satisfied: future~=0.17.1 in /usr/local/lib/python3.6/site-packages (from rasa-nlu~=0.14.0->rasa_core) (0.17.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/site-packages (from packaging~=18.0->rasa_core) (2.3.0)\n",
      "Requirement already satisfied: PyJWT>=1.4.2 in /usr/local/lib/python3.6/site-packages (from twilio~=6.0->rasa_core) (1.7.1)\n",
      "Requirement already satisfied: pysocks; python_version >= \"3.0\" in /usr/local/lib/python3.6/site-packages (from twilio~=6.0->rasa_core) (1.6.8)\n",
      "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.6/site-packages (from webexteamssdk~=1.0->rasa_core) (0.9.1)\n",
      "Requirement already satisfied: greenlet>=0.4.14; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.6/site-packages (from gevent~=1.4->rasa_core) (0.4.15)\n",
      "Requirement already satisfied: cryptography in /usr/local/lib/python3.6/site-packages (from python-telegram-bot~=11.0->rasa_core) (2.6.1)\n",
      "Requirement already satisfied: ConfigArgParse~=0.13.0 in /usr/local/lib/python3.6/site-packages (from rasa-core-sdk~=0.12.1->rasa_core) (0.13.0)\n",
      "Requirement already satisfied: prompt-toolkit~=2.0 in /usr/local/lib/python3.6/site-packages (from questionary>=1.0.1->rasa_core) (2.0.7)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/site-packages (from tensorflow~=1.12.0->rasa_core) (3.6.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/site-packages (from tensorflow~=1.12.0->rasa_core) (1.16.1)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/site-packages (from tensorflow~=1.12.0->rasa_core) (0.6.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/site-packages (from tensorflow~=1.12.0->rasa_core) (0.7.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/site-packages (from tensorflow~=1.12.0->rasa_core) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /usr/local/lib/python3.6/site-packages (from tensorflow~=1.12.0->rasa_core) (1.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/site-packages (from tensorflow~=1.12.0->rasa_core) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/site-packages (from tensorflow~=1.12.0->rasa_core) (0.31.1)\n",
      "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.6/site-packages (from apscheduler~=3.0->rasa_core) (1.5.1)\n",
      "Requirement already satisfied: setuptools>=0.7 in /usr/local/lib/python3.6/site-packages (from apscheduler~=3.0->rasa_core) (39.2.0)\n",
      "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.6/site-packages (from pykwalify~=1.7.0->rasa_core) (3.13)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.6/site-packages (from pykwalify~=1.7.0->rasa_core) (0.6.2)\n",
      "Requirement already satisfied: python-engineio>=3.2.0 in /usr/local/lib/python3.6/site-packages (from python-socketio~=3.0->rasa_core) (3.4.3)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/site-packages (from flask~=1.0->rasa_core) (1.1.0)\n",
      "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.6/site-packages (from flask~=1.0->rasa_core) (2.10)\n",
      "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/site-packages (from flask~=1.0->rasa_core) (7.0)\n",
      "Requirement already satisfied: Werkzeug>=0.14 in /usr/local/lib/python3.6/site-packages (from flask~=1.0->rasa_core) (0.14.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/site-packages (from networkx~=2.2->rasa_core) (4.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/site-packages (from matplotlib~=2.0->rasa-nlu~=0.14.0->rasa_core) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/site-packages (from matplotlib~=2.0->rasa-nlu~=0.14.0->rasa_core) (1.0.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/site-packages (from boto3~=1.5->rasa-nlu~=0.14.0->rasa_core) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/site-packages (from boto3~=1.5->rasa-nlu~=0.14.0->rasa_core) (0.2.0)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.113 in /usr/local/lib/python3.6/site-packages (from boto3~=1.5->rasa-nlu~=0.14.0->rasa_core) (1.12.113)\n",
      "Requirement already satisfied: Twisted>=15.5 in /usr/local/lib/python3.6/site-packages (from klein~=17.10->rasa-nlu~=0.14.0->rasa_core) (18.9.0)\n",
      "Requirement already satisfied: incremental in /usr/local/lib/python3.6/site-packages (from klein~=17.10->rasa-nlu~=0.14.0->rasa_core) (17.5.0)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/site-packages (from cryptography->python-telegram-bot~=11.0->rasa_core) (1.12.2)\n",
      "Requirement already satisfied: asn1crypto>=0.21.0 in /usr/local/lib/python3.6/site-packages (from cryptography->python-telegram-bot~=11.0->rasa_core) (0.24.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/site-packages (from prompt-toolkit~=2.0->questionary>=1.0.1->rasa_core) (0.1.7)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/site-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow~=1.12.0->rasa_core) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/site-packages (from Jinja2>=2.10->flask~=1.0->rasa_core) (1.1.0)\n",
      "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.113->boto3~=1.5->rasa-nlu~=0.14.0->rasa_core) (0.14)\n",
      "Requirement already satisfied: Automat>=0.3.0 in /usr/local/lib/python3.6/site-packages (from Twisted>=15.5->klein~=17.10->rasa-nlu~=0.14.0->rasa_core) (0.7.0)\n",
      "Requirement already satisfied: PyHamcrest>=1.9.0 in /usr/local/lib/python3.6/site-packages (from Twisted>=15.5->klein~=17.10->rasa-nlu~=0.14.0->rasa_core) (1.9.0)\n",
      "Requirement already satisfied: zope.interface>=4.4.2 in /usr/local/lib/python3.6/site-packages (from Twisted>=15.5->klein~=17.10->rasa-nlu~=0.14.0->rasa_core) (4.6.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/site-packages (from Twisted>=15.5->klein~=17.10->rasa-nlu~=0.14.0->rasa_core) (19.1.0)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in /usr/local/lib/python3.6/site-packages (from Twisted>=15.5->klein~=17.10->rasa-nlu~=0.14.0->rasa_core) (18.0.0)\n",
      "Requirement already satisfied: constantly>=15.1 in /usr/local/lib/python3.6/site-packages (from Twisted>=15.5->klein~=17.10->rasa-nlu~=0.14.0->rasa_core) (15.1.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.8->cryptography->python-telegram-bot~=11.0->rasa_core) (2.19)\n"
     ]
    }
   ],
   "source": [
    "!pip install rasa_core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yHYeAA859JGq",
    "pycharm": {}
   },
   "source": [
    "# Importing the Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TSw6zFmk3iPu",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import rasa_nlu\n",
    "import rasa_core\n",
    "import spacy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aEw5vhSq9gWa",
    "pycharm": {}
   },
   "source": [
    "# 1. Teaching the bot to understand user inputs using Rasa NLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oDEAOmaI9o4a",
    "pycharm": {}
   },
   "source": [
    "## Preparing the NLU Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RPxeQ1_14CjK",
    "outputId": "bfb5974f-f8ea-46b8-b8cb-9dd4479ed9cc",
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "nlu_md = \"\"\"\n",
    "## intent:greet\n",
    "- hey\n",
    "- hello there\n",
    "- hi\n",
    "- hello there\n",
    "- good morning\n",
    "- good evening\n",
    "- moin\n",
    "- hey there\n",
    "- let's go\n",
    "- hey dude\n",
    "- goodmorning\n",
    "- goodevening\n",
    "- good afternoon\n",
    "\n",
    "## intent:goodbye\n",
    "- cu\n",
    "- good by\n",
    "- cee you later\n",
    "- good night\n",
    "- good afternoon\n",
    "- bye\n",
    "- goodbye\n",
    "- have a nice day\n",
    "- see you around\n",
    "- bye bye\n",
    "- see you later\n",
    "\n",
    "## intent:mood_affirm\n",
    "- yes\n",
    "- indeed\n",
    "- of course\n",
    "- that sounds good\n",
    "- correct\n",
    "\n",
    "## intent:mood_deny\n",
    "- no\n",
    "- never\n",
    "- I don't think so\n",
    "- don't like that\n",
    "- no way\n",
    "- not really\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## intent:student_work_authorization\n",
    "- What does the student’s work authorization look like?\n",
    "- how is student work authorization?\n",
    "- how does student work authorization look like?\n",
    "- Student work authorization look?\n",
    "- what's Student work authorization\n",
    "\n",
    "## intent:student_work\n",
    "- When can a student work?\n",
    "- When can I work?\n",
    "\n",
    "\n",
    "## intent:student_work_timings\n",
    "- How many hours per week can a student work?\n",
    "- How many hours can I work?\n",
    "- number of hours I can work?\n",
    "- no. of hours I can work?\n",
    "\n",
    "## intent:taxes\n",
    "- Are F-1 students subject to taxes?\n",
    "- am I subjected to tax ?\n",
    "- how much tax shoud I pay ?\n",
    "- should I pay tax ?\n",
    "\n",
    "## intent:E_verify\n",
    "- What is E-Verify?\n",
    "- how to do e-verify?\n",
    "- What is E Verify?\n",
    "- how to do e verify?\n",
    "- What is EVerify?\n",
    "- how to do everify\n",
    "\n",
    "##intent: Visa_interview\n",
    "-What all do I need for Visa Interview?\n",
    "-what all documents do I need for Visa Interview?\n",
    "-Documents needed for Visa Interview?\n",
    "-What all things do I need for Visa Interview?\n",
    "-What all papaers do I need for Visa Interview?\n",
    "\n",
    "##intent: travel_date\n",
    "-When can I travel to the usa?\n",
    "-How many days prior to my admission can I travel to the USA?\n",
    "\n",
    "## intent:customs_immigration\n",
    "-What all do I need for customs and immigration?\n",
    "-what all documents do I need for customs and immigration?\n",
    "-Documents needed for customs and immigration?\n",
    "-What all things do I need for customs and immigration?\n",
    "-What all papaers do I need for customs and immigration?\n",
    "\n",
    "##intent:questions_during_visa\n",
    "-What are the common questions asked during Visa interview?\n",
    "-What should I prepare for Visa interview?\n",
    "-What kind of questions are asked during a visa interview?\n",
    "-Common questions durin Visa interview?\n",
    "-Questions asked in a Visa interview?\n",
    "\n",
    "##intent:health_insurance\n",
    "-How do I pyrchase University heath insurance?\n",
    "-What steps are involved in purchasing student health insurance?\n",
    "-Steps to purchase health insurance?\n",
    "-international Heath Insurance puchase?\n",
    "\n",
    "##intent:immunization\n",
    "-What are the steps involved in immunization?\n",
    "-What all immunization do I need before getting to the USA?\n",
    "-Kind of immunization required before reaching?\n",
    "-What is the proof of immunization that needs to be submitted?\n",
    "\n",
    "##intent:housing\n",
    "-Where can I find the housing details of SJSU?\n",
    "-Accomodation in SJSU?\n",
    "-Accomodation for international students at SJSU?\n",
    "-Housing for students near SJSU?\n",
    "-Housing on campus?\n",
    "\n",
    "##intent:course_registration\n",
    "-How many courses do I need to register for?\n",
    "-How many credits are mandatory?\n",
    "-Number of credits at SJSU?\n",
    "-SJSU credits for F1 students?\n",
    "\n",
    "##intent:tution\n",
    "-Where can I find details about my tution fees?\n",
    "-Information about tution fees?\n",
    "-When do I have to pay for tution fees?\n",
    "-When can I register for the courses?\n",
    "-Where do I pay my tution?\n",
    "\n",
    "##intent:tower_ID\n",
    "-Where can I get my ID?\n",
    "-Do I need an ID?\n",
    "-Procedure to get an ID?\n",
    "-Documents required to get an ID?\n",
    "-How do I get my student ID?\n",
    "-Steps involved in getting student ID card?\n",
    "\n",
    "## intent: inform\n",
    "- A [dog](group:shibes)\n",
    "- [dog](group:shibes)\n",
    "- [bird](group:birds)\n",
    "- a [cat](group:cats)\n",
    "- [cat](group:cats)\n",
    "- a [bird](group:birds)\n",
    "- of a [dog](group:shibes)\n",
    "- of a [cat](group:cats)\n",
    "- a [bird](group:birds), please\n",
    "- a [dog](group:shibes), please\n",
    "\"\"\"\n",
    "\n",
    "%store nlu_md > nlu.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatbot_config.py                nlu_model.py\r\n",
      "config.yml                       policy_config.yml\r\n",
      "domain.yml                       slack_connector.py\r\n",
      "errors.json                      stories.md\r\n",
      "\u001b[34mmodels\u001b[m\u001b[m/                          stories_backup.md\r\n",
      "nlu.md                           story_graph.png\r\n",
      "nlu_config.yml                   student_assistant_chatbot.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ceazcacn9veB",
    "pycharm": {}
   },
   "source": [
    "## Defining the NLU Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dF60NWhR4ID6",
    "outputId": "92946645-94fc-4450-aa41-eca8895ff83c",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'config' (str) to file 'nlu_config.yml'.\n"
     ]
    }
   ],
   "source": [
    "config = \"\"\"\n",
    "language: \"en\"\n",
    "\n",
    "pipeline:\n",
    "- name: \"nlp_spacy\"\n",
    "- name: \"tokenizer_spacy\"\n",
    "- name: \"intent_entity_featurizer_regex\"\n",
    "- name: \"intent_featurizer_spacy\"\n",
    "- name: \"ner_crf\"\n",
    "- name: \"ner_synonyms\"\n",
    "- name: \"intent_classifier_sklearn\"\n",
    "\"\"\"\n",
    "\n",
    "%store config > nlu_config.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'config' (str) to file 'nlu_config.yml'.\n"
     ]
    }
   ],
   "source": [
    "config = \"\"\"\n",
    "language: \"en\"\n",
    "\n",
    "pipeline:\n",
    "- name: \"tokenizer_whitespace\"\n",
    "- name: \"ner_crf\"\n",
    "- name: \"ner_synonyms\"\n",
    "- name: \"intent_featurizer_count_vectors\"\n",
    "- name: \"intent_classifier_tensorflow_embedding\"\n",
    "- name: \"ner_duckling_http\"\n",
    "  url: \"http://127.0.0.1:8000\"\n",
    "  dimensions: [\"time\"] \n",
    "\"\"\"\n",
    "\n",
    "%store config > nlu_config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ieoWk91X9y8X",
    "pycharm": {}
   },
   "source": [
    "## Training the NLU Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "dp3AIHmS4L6x",
    "outputId": "8011c4f7-c789-4138-84d7-4710207615d8",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_nlu.training_data.loading:Training data format of nlu.md is md\n",
      "INFO:rasa_nlu.training_data.training_data:Training data stats: \n",
      "\t- intent examples: 104 (20 distinct intents)\n",
      "\t- Found intents: 'student_work_timings', 'tution', 'questions_during_visa', 'E_verify', 'health_insurance', 'housing', 'student_work', 'greet', 'tower_ID', 'goodbye', 'travel_date', 'inform', 'student_work_authorization', 'course_registration', 'customs_immigration', 'taxes', 'immunization', 'mood_affirm', 'Visa_interview', 'mood_deny'\n",
      "\t- entity examples: 3 (1 distinct entities)\n",
      "\t- found entities: 'events'\n",
      "\n",
      "INFO:rasa_nlu.model:Starting to train component tokenizer_whitespace\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component ner_crf\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component ner_synonyms\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component intent_featurizer_count_vectors\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component intent_classifier_tensorflow_embedding\n",
      "INFO:rasa_nlu.classifiers.embedding_intent_classifier:Accuracy is updated every 10 epochs\n",
      "Epochs: 100%|██████████| 300/300 [00:02<00:00, 119.64it/s, loss=0.166, acc=0.990]\n",
      "INFO:rasa_nlu.classifiers.embedding_intent_classifier:Finished training embedding classifier, loss=0.166, train accuracy=0.990\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component ner_duckling_http\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Successfully saved model into '/Users/saching12/Desktop/python codes/student_assistant_chatbot/models/nlu/default/current'\n"
     ]
    }
   ],
   "source": [
    "from rasa_nlu.training_data import load_data\n",
    "from rasa_nlu.config import RasaNLUModelConfig\n",
    "from rasa_nlu.model import Trainer\n",
    "from rasa_nlu import config\n",
    "\n",
    "# loading the nlu training samples\n",
    "training_data = load_data(\"nlu.md\")\n",
    "\n",
    "# trainer to educate our pipeline\n",
    "trainer = Trainer(config.load(\"nlu_config.yml\"))\n",
    "\n",
    "# train the model!\n",
    "interpreter = trainer.train(training_data)\n",
    "\n",
    "# store it for future use\n",
    "model_directory = trainer.persist(\"./models/nlu\", fixed_model_name=\"current\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jrfp4xOS95ZZ",
    "pycharm": {}
   },
   "source": [
    "## Evaluating the NLU model on a random text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "4UjzlqMV4N1k",
    "outputId": "37ea93e5-6a71-4e8e-d2b6-a45144d184ad",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"inform\",\n",
      "    \"confidence\": 0.9217749834060669\n",
      "  },\n",
      "  \"entities\": [\n",
      "    {\n",
      "      \"start\": 13,\n",
      "      \"end\": 18,\n",
      "      \"value\": \"event\",\n",
      "      \"entity\": \"events\",\n",
      "      \"confidence\": 0.8924925786107403,\n",
      "      \"extractor\": \"ner_crf\"\n",
      "    },\n",
      "    {\n",
      "      \"start\": 19,\n",
      "      \"end\": 40,\n",
      "      \"text\": \"on day after tomorrow\",\n",
      "      \"value\": \"2019-04-18T00:00:00.000-07:00\",\n",
      "      \"confidence\": 1.0,\n",
      "      \"additional_info\": {\n",
      "        \"values\": [\n",
      "          {\n",
      "            \"value\": \"2019-04-18T00:00:00.000-07:00\",\n",
      "            \"grain\": \"day\",\n",
      "            \"type\": \"value\"\n",
      "          }\n",
      "        ],\n",
      "        \"value\": \"2019-04-18T00:00:00.000-07:00\",\n",
      "        \"grain\": \"day\",\n",
      "        \"type\": \"value\"\n",
      "      },\n",
      "      \"entity\": \"time\",\n",
      "      \"extractor\": \"ner_duckling_http\"\n",
      "    }\n",
      "  ],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.9217749834060669\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.23540902137756348\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"student_work\",\n",
      "      \"confidence\": 0.1535656750202179\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"mood_deny\",\n",
      "      \"confidence\": 0.10397358238697052\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"taxes\",\n",
      "      \"confidence\": 0.10274221748113632\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.09450532495975494\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"customs_immigration\",\n",
      "      \"confidence\": 0.07463298738002777\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"mood_affirm\",\n",
      "      \"confidence\": 0.004936873912811279\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"E_verify\",\n",
      "      \"confidence\": 0.0023534968495368958\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"health_insurance\",\n",
      "      \"confidence\": 0.0\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"is there any event on day after tomorrow ? \"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# A helper function for prettier output\n",
    "import json\n",
    "def pprint(o):   \n",
    "    print(json.dumps(o, indent=2))\n",
    "    \n",
    "pprint(interpreter.parse(\"is there any event on day after tomorrow ? \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OPlSd-As-Fz4",
    "pycharm": {}
   },
   "source": [
    "## Evaluating the NLU model on a test data\n",
    "(Here we are using the data at hand i.e nlu.md but it isr recommended to use unseen data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1483
    },
    "colab_type": "code",
    "id": "FmRCylbT4jyw",
    "outputId": "fd1bfd57-ebb3-4541-d3b3-b4cbba781164",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/saching12/Desktop/python codes/student_assistant_chatbot/./models/nlu/default/current/intent_classifier_tensorflow_embedding.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/saching12/Desktop/python codes/student_assistant_chatbot/./models/nlu/default/current/intent_classifier_tensorflow_embedding.ckpt\n",
      "INFO:rasa_nlu.training_data.loading:Training data format of nlu.md is md\n",
      "INFO:rasa_nlu.training_data.training_data:Training data stats: \n",
      "\t- intent examples: 104 (20 distinct intents)\n",
      "\t- Found intents: 'student_work_timings', 'tution', 'questions_during_visa', 'E_verify', 'health_insurance', 'housing', 'student_work', 'greet', 'tower_ID', 'goodbye', 'travel_date', 'inform', 'student_work_authorization', 'course_registration', 'customs_immigration', 'taxes', 'immunization', 'mood_affirm', 'Visa_interview', 'mood_deny'\n",
      "\t- entity examples: 3 (1 distinct entities)\n",
      "\t- found entities: 'events'\n",
      "\n",
      "INFO:rasa_nlu.evaluate:Skipping evaluation of ner_duckling_http\n",
      "INFO:rasa_nlu.evaluate:Intent evaluation results:\n",
      "INFO:rasa_nlu.evaluate:Intent Evaluation: Only considering those 104 examples that have a defined intent out of 104 examples\n",
      "INFO:rasa_nlu.evaluate:F1-Score:  0.9903337403337402\n",
      "INFO:rasa_nlu.evaluate:Precision: 0.9910714285714286\n",
      "INFO:rasa_nlu.evaluate:Accuracy:  0.9903846153846154\n",
      "INFO:rasa_nlu.evaluate:Classification report: \n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                  E_verify       1.00      1.00      1.00         6\n",
      "            Visa_interview       1.00      1.00      1.00         5\n",
      "       course_registration       1.00      1.00      1.00         4\n",
      "       customs_immigration       1.00      1.00      1.00         5\n",
      "                   goodbye       1.00      0.91      0.95        11\n",
      "                     greet       0.93      1.00      0.96        13\n",
      "          health_insurance       1.00      1.00      1.00         4\n",
      "                   housing       1.00      1.00      1.00         5\n",
      "              immunization       1.00      1.00      1.00         4\n",
      "                    inform       1.00      1.00      1.00         3\n",
      "               mood_affirm       1.00      1.00      1.00         5\n",
      "                 mood_deny       1.00      1.00      1.00         6\n",
      "     questions_during_visa       1.00      1.00      1.00         5\n",
      "              student_work       1.00      1.00      1.00         2\n",
      "student_work_authorization       1.00      1.00      1.00         5\n",
      "      student_work_timings       1.00      1.00      1.00         4\n",
      "                     taxes       1.00      1.00      1.00         4\n",
      "                  tower_ID       1.00      1.00      1.00         6\n",
      "               travel_date       1.00      1.00      1.00         2\n",
      "                    tution       1.00      1.00      1.00         5\n",
      "\n",
      "                 micro avg       0.99      0.99      0.99       104\n",
      "                 macro avg       1.00      1.00      1.00       104\n",
      "              weighted avg       0.99      0.99      0.99       104\n",
      "\n",
      "INFO:rasa_nlu.evaluate:Model prediction errors saved to errors.json.\n",
      "INFO:rasa_nlu.evaluate:Entity evaluation results:\n",
      "INFO:rasa_nlu.evaluate:Evaluation for entity extractor: ner_crf \n",
      "INFO:rasa_nlu.evaluate:F1-Score:  1.0\n",
      "INFO:rasa_nlu.evaluate:Precision: 1.0\n",
      "INFO:rasa_nlu.evaluate:Accuracy:  1.0\n",
      "INFO:rasa_nlu.evaluate:Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      events       1.00      1.00      1.00         3\n",
      "   no_entity       1.00      1.00      1.00       514\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       517\n",
      "   macro avg       1.00      1.00      1.00       517\n",
      "weighted avg       1.00      1.00      1.00       517\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'intent_evaluation': {'predictions': [{'text': 'hey',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.9697084426879883},\n",
       "   {'text': 'hello there',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.9683195352554321},\n",
       "   {'text': 'hi',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.9640589952468872},\n",
       "   {'text': 'hello there',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.9683195352554321},\n",
       "   {'text': 'good morning',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.9776124358177185},\n",
       "   {'text': 'good evening',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.9719564318656921},\n",
       "   {'text': 'moin',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.9577948451042175},\n",
       "   {'text': 'hey there',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.9623345732688904},\n",
       "   {'text': \"let's go\",\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.9815815687179565},\n",
       "   {'text': 'hey dude',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.9782136678695679},\n",
       "   {'text': 'good morning',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.9776124358177185},\n",
       "   {'text': 'good evening',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.9719564318656921},\n",
       "   {'text': 'good afternoon',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.7381491661071777},\n",
       "   {'text': 'cu',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.924860954284668},\n",
       "   {'text': 'good by',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.9245909452438354},\n",
       "   {'text': 'cee you later',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.9654041528701782},\n",
       "   {'text': 'good night',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.9531242251396179},\n",
       "   {'text': 'good afternoon',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.7381491661071777},\n",
       "   {'text': 'bye',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.9360664486885071},\n",
       "   {'text': 'goodbye',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.9208492040634155},\n",
       "   {'text': 'have a nice day',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.9476683735847473},\n",
       "   {'text': 'see you around',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.9613560438156128},\n",
       "   {'text': 'bye bye',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.9586060047149658},\n",
       "   {'text': 'see you later',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.9674496054649353},\n",
       "   {'text': 'yes',\n",
       "    'intent': 'mood_affirm',\n",
       "    'predicted': 'mood_affirm',\n",
       "    'confidence': 0.935373067855835},\n",
       "   {'text': 'indeed',\n",
       "    'intent': 'mood_affirm',\n",
       "    'predicted': 'mood_affirm',\n",
       "    'confidence': 0.9210599064826965},\n",
       "   {'text': 'of course',\n",
       "    'intent': 'mood_affirm',\n",
       "    'predicted': 'mood_affirm',\n",
       "    'confidence': 0.9109625220298767},\n",
       "   {'text': 'that sounds good',\n",
       "    'intent': 'mood_affirm',\n",
       "    'predicted': 'mood_affirm',\n",
       "    'confidence': 0.9416934847831726},\n",
       "   {'text': 'correct',\n",
       "    'intent': 'mood_affirm',\n",
       "    'predicted': 'mood_affirm',\n",
       "    'confidence': 0.9367388486862183},\n",
       "   {'text': 'no',\n",
       "    'intent': 'mood_deny',\n",
       "    'predicted': 'mood_deny',\n",
       "    'confidence': 0.942272424697876},\n",
       "   {'text': 'never',\n",
       "    'intent': 'mood_deny',\n",
       "    'predicted': 'mood_deny',\n",
       "    'confidence': 0.9286998510360718},\n",
       "   {'text': \"I don't think so\",\n",
       "    'intent': 'mood_deny',\n",
       "    'predicted': 'mood_deny',\n",
       "    'confidence': 0.9485076665878296},\n",
       "   {'text': \"don't like that\",\n",
       "    'intent': 'mood_deny',\n",
       "    'predicted': 'mood_deny',\n",
       "    'confidence': 0.9633979797363281},\n",
       "   {'text': 'no way',\n",
       "    'intent': 'mood_deny',\n",
       "    'predicted': 'mood_deny',\n",
       "    'confidence': 0.941922664642334},\n",
       "   {'text': 'not really',\n",
       "    'intent': 'mood_deny',\n",
       "    'predicted': 'mood_deny',\n",
       "    'confidence': 0.9412391185760498},\n",
       "   {'text': 'What does the student’s work authorization look like?',\n",
       "    'intent': 'student_work_authorization',\n",
       "    'predicted': 'student_work_authorization',\n",
       "    'confidence': 0.9741086959838867},\n",
       "   {'text': 'how is student work authorization?',\n",
       "    'intent': 'student_work_authorization',\n",
       "    'predicted': 'student_work_authorization',\n",
       "    'confidence': 0.9720228314399719},\n",
       "   {'text': 'how does student work authorization look like?',\n",
       "    'intent': 'student_work_authorization',\n",
       "    'predicted': 'student_work_authorization',\n",
       "    'confidence': 0.9781456589698792},\n",
       "   {'text': 'Student work authorization look?',\n",
       "    'intent': 'student_work_authorization',\n",
       "    'predicted': 'student_work_authorization',\n",
       "    'confidence': 0.9799925088882446},\n",
       "   {'text': \"what's Student work authorization\",\n",
       "    'intent': 'student_work_authorization',\n",
       "    'predicted': 'student_work_authorization',\n",
       "    'confidence': 0.9749875068664551},\n",
       "   {'text': 'When can a student work?',\n",
       "    'intent': 'student_work',\n",
       "    'predicted': 'student_work',\n",
       "    'confidence': 0.9576306939125061},\n",
       "   {'text': 'When can I work?',\n",
       "    'intent': 'student_work',\n",
       "    'predicted': 'student_work',\n",
       "    'confidence': 0.9569044709205627},\n",
       "   {'text': 'How many hours per week can a student work?',\n",
       "    'intent': 'student_work_timings',\n",
       "    'predicted': 'student_work_timings',\n",
       "    'confidence': 0.9469345211982727},\n",
       "   {'text': 'How many hours can I work?',\n",
       "    'intent': 'student_work_timings',\n",
       "    'predicted': 'student_work_timings',\n",
       "    'confidence': 0.9496782422065735},\n",
       "   {'text': 'number of hours I can work?',\n",
       "    'intent': 'student_work_timings',\n",
       "    'predicted': 'student_work_timings',\n",
       "    'confidence': 0.951732337474823},\n",
       "   {'text': 'no. of hours I can work?',\n",
       "    'intent': 'student_work_timings',\n",
       "    'predicted': 'student_work_timings',\n",
       "    'confidence': 0.9641115665435791},\n",
       "   {'text': 'Are F-1 students subject to taxes?',\n",
       "    'intent': 'taxes',\n",
       "    'predicted': 'taxes',\n",
       "    'confidence': 0.9281023144721985},\n",
       "   {'text': 'am I subjected to tax ?',\n",
       "    'intent': 'taxes',\n",
       "    'predicted': 'taxes',\n",
       "    'confidence': 0.9340642690658569},\n",
       "   {'text': 'how much tax shoud I pay ?',\n",
       "    'intent': 'taxes',\n",
       "    'predicted': 'taxes',\n",
       "    'confidence': 0.948839008808136},\n",
       "   {'text': 'should I pay tax ?',\n",
       "    'intent': 'taxes',\n",
       "    'predicted': 'taxes',\n",
       "    'confidence': 0.9213594198226929},\n",
       "   {'text': 'What is E-Verify?',\n",
       "    'intent': 'E_verify',\n",
       "    'predicted': 'E_verify',\n",
       "    'confidence': 0.9428467750549316},\n",
       "   {'text': 'how to do e-verify?',\n",
       "    'intent': 'E_verify',\n",
       "    'predicted': 'E_verify',\n",
       "    'confidence': 0.9454026222229004},\n",
       "   {'text': 'What is E Verify?',\n",
       "    'intent': 'E_verify',\n",
       "    'predicted': 'E_verify',\n",
       "    'confidence': 0.9428467750549316},\n",
       "   {'text': 'how to do e verify?',\n",
       "    'intent': 'E_verify',\n",
       "    'predicted': 'E_verify',\n",
       "    'confidence': 0.9454026222229004},\n",
       "   {'text': 'What is EVerify?',\n",
       "    'intent': 'E_verify',\n",
       "    'predicted': 'E_verify',\n",
       "    'confidence': 0.955499529838562},\n",
       "   {'text': 'how to do everify',\n",
       "    'intent': 'E_verify',\n",
       "    'predicted': 'E_verify',\n",
       "    'confidence': 0.9474855065345764},\n",
       "   {'text': 'What all do I need for Visa Interview?',\n",
       "    'intent': 'Visa_interview',\n",
       "    'predicted': 'Visa_interview',\n",
       "    'confidence': 0.9515243172645569},\n",
       "   {'text': 'what all documents do I need for Visa Interview?',\n",
       "    'intent': 'Visa_interview',\n",
       "    'predicted': 'Visa_interview',\n",
       "    'confidence': 0.9573076963424683},\n",
       "   {'text': 'Documents needed for Visa Interview?',\n",
       "    'intent': 'Visa_interview',\n",
       "    'predicted': 'Visa_interview',\n",
       "    'confidence': 0.9549334645271301},\n",
       "   {'text': 'What all things do I need for Visa Interview?',\n",
       "    'intent': 'Visa_interview',\n",
       "    'predicted': 'Visa_interview',\n",
       "    'confidence': 0.9537105560302734},\n",
       "   {'text': 'What all papaers do I need for Visa Interview?',\n",
       "    'intent': 'Visa_interview',\n",
       "    'predicted': 'Visa_interview',\n",
       "    'confidence': 0.9537184834480286},\n",
       "   {'text': 'When can I travel to the usa?',\n",
       "    'intent': 'travel_date',\n",
       "    'predicted': 'travel_date',\n",
       "    'confidence': 0.9667178392410278},\n",
       "   {'text': 'How many days prior to my admission can I travel to the USA?',\n",
       "    'intent': 'travel_date',\n",
       "    'predicted': 'travel_date',\n",
       "    'confidence': 0.9568054676055908},\n",
       "   {'text': 'What all do I need for customs and immigration?',\n",
       "    'intent': 'customs_immigration',\n",
       "    'predicted': 'customs_immigration',\n",
       "    'confidence': 0.9371835589408875},\n",
       "   {'text': 'what all documents do I need for customs and immigration?',\n",
       "    'intent': 'customs_immigration',\n",
       "    'predicted': 'customs_immigration',\n",
       "    'confidence': 0.9409178495407104},\n",
       "   {'text': 'Documents needed for customs and immigration?',\n",
       "    'intent': 'customs_immigration',\n",
       "    'predicted': 'customs_immigration',\n",
       "    'confidence': 0.9382894039154053},\n",
       "   {'text': 'What all things do I need for customs and immigration?',\n",
       "    'intent': 'customs_immigration',\n",
       "    'predicted': 'customs_immigration',\n",
       "    'confidence': 0.9427186250686646},\n",
       "   {'text': 'What all papaers do I need for customs and immigration?',\n",
       "    'intent': 'customs_immigration',\n",
       "    'predicted': 'customs_immigration',\n",
       "    'confidence': 0.9392043948173523},\n",
       "   {'text': 'What are the common questions asked during Visa interview?',\n",
       "    'intent': 'questions_during_visa',\n",
       "    'predicted': 'questions_during_visa',\n",
       "    'confidence': 0.9628332853317261},\n",
       "   {'text': 'What should I prepare for Visa interview?',\n",
       "    'intent': 'questions_during_visa',\n",
       "    'predicted': 'questions_during_visa',\n",
       "    'confidence': 0.9511817693710327},\n",
       "   {'text': 'What kind of questions are asked during a visa interview?',\n",
       "    'intent': 'questions_during_visa',\n",
       "    'predicted': 'questions_during_visa',\n",
       "    'confidence': 0.9435924291610718},\n",
       "   {'text': 'Common questions durin Visa interview?',\n",
       "    'intent': 'questions_during_visa',\n",
       "    'predicted': 'questions_during_visa',\n",
       "    'confidence': 0.9580684900283813},\n",
       "   {'text': 'Questions asked in a Visa interview?',\n",
       "    'intent': 'questions_during_visa',\n",
       "    'predicted': 'questions_during_visa',\n",
       "    'confidence': 0.9454033970832825},\n",
       "   {'text': 'How do I pyrchase University heath insurance?',\n",
       "    'intent': 'health_insurance',\n",
       "    'predicted': 'health_insurance',\n",
       "    'confidence': 0.9390663504600525},\n",
       "   {'text': 'What steps are involved in purchasing student health insurance?',\n",
       "    'intent': 'health_insurance',\n",
       "    'predicted': 'health_insurance',\n",
       "    'confidence': 0.934541642665863},\n",
       "   {'text': 'Steps to purchase health insurance?',\n",
       "    'intent': 'health_insurance',\n",
       "    'predicted': 'health_insurance',\n",
       "    'confidence': 0.9517495632171631},\n",
       "   {'text': 'international Heath Insurance puchase?',\n",
       "    'intent': 'health_insurance',\n",
       "    'predicted': 'health_insurance',\n",
       "    'confidence': 0.9514526128768921},\n",
       "   {'text': 'What are the steps involved in immunization?',\n",
       "    'intent': 'immunization',\n",
       "    'predicted': 'immunization',\n",
       "    'confidence': 0.9441537857055664},\n",
       "   {'text': 'What all immunization do I need before getting to the USA?',\n",
       "    'intent': 'immunization',\n",
       "    'predicted': 'immunization',\n",
       "    'confidence': 0.9523351192474365},\n",
       "   {'text': 'Kind of immunization required before reaching?',\n",
       "    'intent': 'immunization',\n",
       "    'predicted': 'immunization',\n",
       "    'confidence': 0.94636470079422},\n",
       "   {'text': 'What is the proof of immunization that needs to be submitted?',\n",
       "    'intent': 'immunization',\n",
       "    'predicted': 'immunization',\n",
       "    'confidence': 0.9426171779632568},\n",
       "   {'text': 'Where can I find the housing details of SJSU?',\n",
       "    'intent': 'housing',\n",
       "    'predicted': 'housing',\n",
       "    'confidence': 0.9414016008377075},\n",
       "   {'text': 'Accomodation in SJSU?',\n",
       "    'intent': 'housing',\n",
       "    'predicted': 'housing',\n",
       "    'confidence': 0.9434261918067932},\n",
       "   {'text': 'Accomodation for international students at SJSU?',\n",
       "    'intent': 'housing',\n",
       "    'predicted': 'housing',\n",
       "    'confidence': 0.9508339762687683},\n",
       "   {'text': 'Housing for students near SJSU?',\n",
       "    'intent': 'housing',\n",
       "    'predicted': 'housing',\n",
       "    'confidence': 0.9519358277320862},\n",
       "   {'text': 'Housing on campus?',\n",
       "    'intent': 'housing',\n",
       "    'predicted': 'housing',\n",
       "    'confidence': 0.9769699573516846},\n",
       "   {'text': 'How many courses do I need to register for?',\n",
       "    'intent': 'course_registration',\n",
       "    'predicted': 'course_registration',\n",
       "    'confidence': 0.9317573308944702},\n",
       "   {'text': 'How many credits are mandatory?',\n",
       "    'intent': 'course_registration',\n",
       "    'predicted': 'course_registration',\n",
       "    'confidence': 0.9363347291946411},\n",
       "   {'text': 'Number of credits at SJSU?',\n",
       "    'intent': 'course_registration',\n",
       "    'predicted': 'course_registration',\n",
       "    'confidence': 0.9449101686477661},\n",
       "   {'text': 'SJSU credits for F1 students?',\n",
       "    'intent': 'course_registration',\n",
       "    'predicted': 'course_registration',\n",
       "    'confidence': 0.9343407154083252},\n",
       "   {'text': 'Where can I find details about my tution fees?',\n",
       "    'intent': 'tution',\n",
       "    'predicted': 'tution',\n",
       "    'confidence': 0.9624543190002441},\n",
       "   {'text': 'Information about tution fees?',\n",
       "    'intent': 'tution',\n",
       "    'predicted': 'tution',\n",
       "    'confidence': 0.9703822135925293},\n",
       "   {'text': 'When do I have to pay for tution fees?',\n",
       "    'intent': 'tution',\n",
       "    'predicted': 'tution',\n",
       "    'confidence': 0.9616786241531372},\n",
       "   {'text': 'When can I register for the courses?',\n",
       "    'intent': 'tution',\n",
       "    'predicted': 'tution',\n",
       "    'confidence': 0.9653586745262146},\n",
       "   {'text': 'Where do I pay my tution?',\n",
       "    'intent': 'tution',\n",
       "    'predicted': 'tution',\n",
       "    'confidence': 0.9612732529640198},\n",
       "   {'text': 'Where can I get my ID?',\n",
       "    'intent': 'tower_ID',\n",
       "    'predicted': 'tower_ID',\n",
       "    'confidence': 0.9561234712600708},\n",
       "   {'text': 'Do I need an ID?',\n",
       "    'intent': 'tower_ID',\n",
       "    'predicted': 'tower_ID',\n",
       "    'confidence': 0.9675769805908203},\n",
       "   {'text': 'Procedure to get an ID?',\n",
       "    'intent': 'tower_ID',\n",
       "    'predicted': 'tower_ID',\n",
       "    'confidence': 0.9622594118118286},\n",
       "   {'text': 'Documents required to get an ID?',\n",
       "    'intent': 'tower_ID',\n",
       "    'predicted': 'tower_ID',\n",
       "    'confidence': 0.962833046913147},\n",
       "   {'text': 'How do I get my student ID?',\n",
       "    'intent': 'tower_ID',\n",
       "    'predicted': 'tower_ID',\n",
       "    'confidence': 0.9522407650947571},\n",
       "   {'text': 'Steps involved in getting student ID card?',\n",
       "    'intent': 'tower_ID',\n",
       "    'predicted': 'tower_ID',\n",
       "    'confidence': 0.9468299150466919},\n",
       "   {'text': 'what event is happening tomorrow?',\n",
       "    'intent': 'inform',\n",
       "    'predicted': 'inform',\n",
       "    'confidence': 0.9502518177032471},\n",
       "   {'text': 'do we have any event today?',\n",
       "    'intent': 'inform',\n",
       "    'predicted': 'inform',\n",
       "    'confidence': 0.9203757047653198},\n",
       "   {'text': 'is there any event on 12th October?',\n",
       "    'intent': 'inform',\n",
       "    'predicted': 'inform',\n",
       "    'confidence': 0.9439394474029541}],\n",
       "  'report': '                            precision    recall  f1-score   support\\n\\n                  E_verify       1.00      1.00      1.00         6\\n            Visa_interview       1.00      1.00      1.00         5\\n       course_registration       1.00      1.00      1.00         4\\n       customs_immigration       1.00      1.00      1.00         5\\n                   goodbye       1.00      0.91      0.95        11\\n                     greet       0.93      1.00      0.96        13\\n          health_insurance       1.00      1.00      1.00         4\\n                   housing       1.00      1.00      1.00         5\\n              immunization       1.00      1.00      1.00         4\\n                    inform       1.00      1.00      1.00         3\\n               mood_affirm       1.00      1.00      1.00         5\\n                 mood_deny       1.00      1.00      1.00         6\\n     questions_during_visa       1.00      1.00      1.00         5\\n              student_work       1.00      1.00      1.00         2\\nstudent_work_authorization       1.00      1.00      1.00         5\\n      student_work_timings       1.00      1.00      1.00         4\\n                     taxes       1.00      1.00      1.00         4\\n                  tower_ID       1.00      1.00      1.00         6\\n               travel_date       1.00      1.00      1.00         2\\n                    tution       1.00      1.00      1.00         5\\n\\n                 micro avg       0.99      0.99      0.99       104\\n                 macro avg       1.00      1.00      1.00       104\\n              weighted avg       0.99      0.99      0.99       104\\n',\n",
       "  'precision': 0.9910714285714286,\n",
       "  'f1_score': 0.9903337403337402,\n",
       "  'accuracy': 0.9903846153846154},\n",
       " 'entity_evaluation': {'ner_crf': {'report': '              precision    recall  f1-score   support\\n\\n      events       1.00      1.00      1.00         3\\n   no_entity       1.00      1.00      1.00       514\\n\\n   micro avg       1.00      1.00      1.00       517\\n   macro avg       1.00      1.00      1.00       517\\nweighted avg       1.00      1.00      1.00       517\\n',\n",
       "   'precision': 1.0,\n",
       "   'f1_score': 1.0,\n",
       "   'accuracy': 1.0}}}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rasa_nlu.evaluate import run_evaluation\n",
    "\n",
    "run_evaluation(\"nlu.md\", model_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Av3R2GZZ-WJO",
    "pycharm": {}
   },
   "source": [
    "# 2. Teaching the bot to respond using Rasa Core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BKZ63AuS-ZPV",
    "pycharm": {}
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ROL3AYs5-iCg",
    "pycharm": {}
   },
   "source": [
    "## Custom Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7SbmLMJa5X0E",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from rasa_core.actions import Action\n",
    "from rasa_core.events import SlotSet\n",
    "from IPython.core.display import Image, display\n",
    "\n",
    "import requests\n",
    "\n",
    "class action_retrieve_event(Action):\n",
    "    def name(self):\n",
    "        return \"action_retrieve_event\"\n",
    "\n",
    "    def run(self, dispatcher, tracker, domain):\n",
    "        \n",
    "        time = tracker.get_slot('time')\n",
    "        #date = time.split('T')[0]\n",
    "        #print(date)\n",
    "        #r = requests.get('http://shibe.online/api/{}?count=1&urls=true&httpsUrls=true'.format(time))\n",
    "        #response = r.content.decode()\n",
    "        #response = response.replace('[\"',\"\")\n",
    "        #response = response.replace('\"]',\"\")\n",
    "   \n",
    "        \n",
    "        #display(Image(response[0], height=550, width=520))\n",
    "        dispatcher.utter_message(\"Here is something to cheer you up: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M-jn1g_k-o-m",
    "pycharm": {}
   },
   "source": [
    "##  Visualising the Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pXZhTaSw9SNR",
    "pycharm": {}
   },
   "source": [
    "## Install these packages\n",
    "!apt-get -qq install -y graphviz libgraphviz-dev pkg-config;\n",
    "!breq install graphviz\n",
    "\n",
    "!{python} -m pip install pygraphviz;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1090
    },
    "colab_type": "code",
    "id": "O1gYRXe15amU",
    "outputId": "9c0838e3-56c1-4eeb-a879-cc09619269d3",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed Story Blocks: 100%|██████████| 49/49 [00:00<00:00, 1097.10it/s, # trackers=1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from IPython.display import Image\n",
    "from rasa_core.agent import Agent\n",
    "\n",
    "agent = Agent('domain.yml')\n",
    "agent.visualize(\"stories.md\", \"story_graph.png\", max_history=2)\n",
    "#Image(filename=\"story_graph.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'config' (str) to file 'policy_config.yml'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = \"\"\"\n",
    "policies:\n",
    "  - name: \"KerasPolicy\"\n",
    "    epochs: 700\n",
    "    featurizer:\n",
    "    - name: MaxHistoryTrackerFeaturizer\n",
    "      max_history: 2\n",
    "      state_featurizer:\n",
    "        - name: BinarySingleStateFeaturizer\n",
    "  - name: \"MemoizationPolicy\"\n",
    "    max_history: 2\n",
    "  - name: \"FallbackPolicy\"\n",
    "    nlu_threshold: 0.5\n",
    "    core_threshold: 0.2\n",
    "    fallback_action_name: \"utter_unclear\"\n",
    "\"\"\" \n",
    "\n",
    "%store config > policy_config.yml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCdKD3l7-ua8",
    "pycharm": {}
   },
   "source": [
    "## Training a Dialogue Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7364
    },
    "colab_type": "code",
    "id": "4D7R-FRO5dxz",
    "outputId": "727adf2a-fa4b-4158-df94-30ad472f62f3",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed Story Blocks: 100%|██████████| 49/49 [00:00<00:00, 1201.74it/s, # trackers=1]\n",
      "Processed Story Blocks: 100%|██████████| 49/49 [00:00<00:00, 530.40it/s, # trackers=5]\n",
      "Processed Story Blocks: 100%|██████████| 49/49 [00:00<00:00, 457.50it/s, # trackers=5]\n",
      "Processed Story Blocks: 100%|██████████| 49/49 [00:00<00:00, 509.68it/s, # trackers=4]\n",
      "INFO:rasa_core.policies.keras_policy:Fitting model with 222 total samples and a validation split of 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking (Masking)            (None, 2, 56)             0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                11392     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 30)                990       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 30)                0         \n",
      "=================================================================\n",
      "Total params: 12,382\n",
      "Trainable params: 12,382\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/700\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.3974 - acc: 0.0495\n",
      "Epoch 2/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 3.3727 - acc: 0.0811\n",
      "Epoch 3/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 3.3519 - acc: 0.1261\n",
      "Epoch 4/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 3.3317 - acc: 0.1081\n",
      "Epoch 5/700\n",
      "222/222 [==============================] - 0s 118us/step - loss: 3.3146 - acc: 0.1126\n",
      "Epoch 6/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 3.2930 - acc: 0.1306\n",
      "Epoch 7/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 3.2770 - acc: 0.1216\n",
      "Epoch 8/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 3.2597 - acc: 0.1306\n",
      "Epoch 9/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 3.2312 - acc: 0.1396\n",
      "Epoch 10/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 3.2130 - acc: 0.1486\n",
      "Epoch 11/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 3.1850 - acc: 0.1802\n",
      "Epoch 12/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 3.1592 - acc: 0.1847\n",
      "Epoch 13/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 3.1292 - acc: 0.1757\n",
      "Epoch 14/700\n",
      "222/222 [==============================] - 0s 118us/step - loss: 3.0992 - acc: 0.1802\n",
      "Epoch 15/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 3.0621 - acc: 0.1712\n",
      "Epoch 16/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 3.0332 - acc: 0.1847\n",
      "Epoch 17/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 2.9997 - acc: 0.1892\n",
      "Epoch 18/700\n",
      "222/222 [==============================] - 0s 117us/step - loss: 2.9799 - acc: 0.1982\n",
      "Epoch 19/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 2.9381 - acc: 0.1982\n",
      "Epoch 20/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 2.9230 - acc: 0.2027\n",
      "Epoch 21/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 2.8884 - acc: 0.2117\n",
      "Epoch 22/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 2.8623 - acc: 0.2072\n",
      "Epoch 23/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 2.8349 - acc: 0.2072\n",
      "Epoch 24/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 2.7838 - acc: 0.2162\n",
      "Epoch 25/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 2.7670 - acc: 0.2252\n",
      "Epoch 26/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 2.7571 - acc: 0.2207\n",
      "Epoch 27/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 2.7124 - acc: 0.2252\n",
      "Epoch 28/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 2.7044 - acc: 0.2252\n",
      "Epoch 29/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 2.6783 - acc: 0.2387\n",
      "Epoch 30/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 2.6126 - acc: 0.2342\n",
      "Epoch 31/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 2.6183 - acc: 0.2207\n",
      "Epoch 32/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 2.5801 - acc: 0.2703\n",
      "Epoch 33/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 2.5456 - acc: 0.2838\n",
      "Epoch 34/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 2.5002 - acc: 0.2748\n",
      "Epoch 35/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 2.4958 - acc: 0.2928\n",
      "Epoch 36/700\n",
      "222/222 [==============================] - 0s 115us/step - loss: 2.4801 - acc: 0.3063\n",
      "Epoch 37/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 2.4686 - acc: 0.3108\n",
      "Epoch 38/700\n",
      "222/222 [==============================] - 0s 115us/step - loss: 2.3856 - acc: 0.3243\n",
      "Epoch 39/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 2.3986 - acc: 0.3514\n",
      "Epoch 40/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 2.3536 - acc: 0.3198\n",
      "Epoch 41/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 2.2992 - acc: 0.3514\n",
      "Epoch 42/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 2.2703 - acc: 0.3784\n",
      "Epoch 43/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 2.2072 - acc: 0.3649\n",
      "Epoch 44/700\n",
      "222/222 [==============================] - 0s 118us/step - loss: 2.1897 - acc: 0.3874\n",
      "Epoch 45/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 2.1372 - acc: 0.4459\n",
      "Epoch 46/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 2.1116 - acc: 0.4414\n",
      "Epoch 47/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 2.0221 - acc: 0.4955\n",
      "Epoch 48/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 2.0993 - acc: 0.5135\n",
      "Epoch 49/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 1.9652 - acc: 0.5946\n",
      "Epoch 50/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 1.9313 - acc: 0.6441\n",
      "Epoch 51/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 1.8882 - acc: 0.6351\n",
      "Epoch 52/700\n",
      "222/222 [==============================] - 0s 101us/step - loss: 1.8464 - acc: 0.6126\n",
      "Epoch 53/700\n",
      "222/222 [==============================] - 0s 116us/step - loss: 1.7850 - acc: 0.7387\n",
      "Epoch 54/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 1.7572 - acc: 0.6622\n",
      "Epoch 55/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 1.7023 - acc: 0.7387\n",
      "Epoch 56/700\n",
      "222/222 [==============================] - 0s 104us/step - loss: 1.6754 - acc: 0.7297\n",
      "Epoch 57/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 1.6235 - acc: 0.7252\n",
      "Epoch 58/700\n",
      "222/222 [==============================] - 0s 116us/step - loss: 1.4990 - acc: 0.8063\n",
      "Epoch 59/700\n",
      "222/222 [==============================] - 0s 120us/step - loss: 1.5801 - acc: 0.7568\n",
      "Epoch 60/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 1.4656 - acc: 0.7883\n",
      "Epoch 61/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 1.4522 - acc: 0.8063\n",
      "Epoch 62/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 1.3973 - acc: 0.8198\n",
      "Epoch 63/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 1.3583 - acc: 0.8018\n",
      "Epoch 64/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 1.3025 - acc: 0.7973\n",
      "Epoch 65/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 1.2977 - acc: 0.8063\n",
      "Epoch 66/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 1.2569 - acc: 0.7973\n",
      "Epoch 67/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 1.2235 - acc: 0.7883\n",
      "Epoch 68/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 1.1409 - acc: 0.8333\n",
      "Epoch 69/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 1.1900 - acc: 0.7928\n",
      "Epoch 70/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 1.2216 - acc: 0.7613\n",
      "Epoch 71/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 1.1150 - acc: 0.8108\n",
      "Epoch 72/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 1.1364 - acc: 0.8063\n",
      "Epoch 73/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.9788 - acc: 0.8514\n",
      "Epoch 74/700\n",
      "222/222 [==============================] - 0s 115us/step - loss: 1.0030 - acc: 0.8333\n",
      "Epoch 75/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222/222 [==============================] - 0s 113us/step - loss: 0.9771 - acc: 0.8243\n",
      "Epoch 76/700\n",
      "222/222 [==============================] - 0s 122us/step - loss: 0.9440 - acc: 0.8333\n",
      "Epoch 77/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 0.9294 - acc: 0.8378\n",
      "Epoch 78/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.8775 - acc: 0.8784\n",
      "Epoch 79/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.9025 - acc: 0.8378\n",
      "Epoch 80/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.9171 - acc: 0.8198\n",
      "Epoch 81/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.8509 - acc: 0.8559\n",
      "Epoch 82/700\n",
      "222/222 [==============================] - 0s 105us/step - loss: 0.8419 - acc: 0.8423\n",
      "Epoch 83/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 0.9652 - acc: 0.8018\n",
      "Epoch 84/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.7596 - acc: 0.8604\n",
      "Epoch 85/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.7703 - acc: 0.8514\n",
      "Epoch 86/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.7746 - acc: 0.8604\n",
      "Epoch 87/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.7741 - acc: 0.8468\n",
      "Epoch 88/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.8191 - acc: 0.8243\n",
      "Epoch 89/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.6133 - acc: 0.9054\n",
      "Epoch 90/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.7550 - acc: 0.8288\n",
      "Epoch 91/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.7166 - acc: 0.8423\n",
      "Epoch 92/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.7707 - acc: 0.8288\n",
      "Epoch 93/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.7296 - acc: 0.8559\n",
      "Epoch 94/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.7417 - acc: 0.8333\n",
      "Epoch 95/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.7396 - acc: 0.8378\n",
      "Epoch 96/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 0.6502 - acc: 0.8604\n",
      "Epoch 97/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.6909 - acc: 0.8378\n",
      "Epoch 98/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.6890 - acc: 0.8468\n",
      "Epoch 99/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.5667 - acc: 0.8829\n",
      "Epoch 100/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 0.6077 - acc: 0.8649\n",
      "Epoch 101/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.6767 - acc: 0.8378\n",
      "Epoch 102/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.6256 - acc: 0.8514\n",
      "Epoch 103/700\n",
      "222/222 [==============================] - 0s 118us/step - loss: 0.6909 - acc: 0.8288\n",
      "Epoch 104/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 0.5604 - acc: 0.8649\n",
      "Epoch 105/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.5957 - acc: 0.8514\n",
      "Epoch 106/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.5551 - acc: 0.8694\n",
      "Epoch 107/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.5315 - acc: 0.8739\n",
      "Epoch 108/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.5546 - acc: 0.8694\n",
      "Epoch 109/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.6398 - acc: 0.8333\n",
      "Epoch 110/700\n",
      "222/222 [==============================] - 0s 117us/step - loss: 0.5167 - acc: 0.8874\n",
      "Epoch 111/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.6094 - acc: 0.8333\n",
      "Epoch 112/700\n",
      "222/222 [==============================] - 0s 118us/step - loss: 0.5051 - acc: 0.8739\n",
      "Epoch 113/700\n",
      "222/222 [==============================] - 0s 105us/step - loss: 0.5034 - acc: 0.8739\n",
      "Epoch 114/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.4674 - acc: 0.9009\n",
      "Epoch 115/700\n",
      "222/222 [==============================] - 0s 105us/step - loss: 0.5247 - acc: 0.8874\n",
      "Epoch 116/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.5845 - acc: 0.8649\n",
      "Epoch 117/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.5798 - acc: 0.8514\n",
      "Epoch 118/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.4975 - acc: 0.8874\n",
      "Epoch 119/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.5392 - acc: 0.8694\n",
      "Epoch 120/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.5460 - acc: 0.8514\n",
      "Epoch 121/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.5149 - acc: 0.8784\n",
      "Epoch 122/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.6086 - acc: 0.8514\n",
      "Epoch 123/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.4415 - acc: 0.9144\n",
      "Epoch 124/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.5447 - acc: 0.8739\n",
      "Epoch 125/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.5369 - acc: 0.8694\n",
      "Epoch 126/700\n",
      "222/222 [==============================] - 0s 104us/step - loss: 0.5685 - acc: 0.8649\n",
      "Epoch 127/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.5313 - acc: 0.8739\n",
      "Epoch 128/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.4379 - acc: 0.8964\n",
      "Epoch 129/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.5322 - acc: 0.8378\n",
      "Epoch 130/700\n",
      "222/222 [==============================] - 0s 105us/step - loss: 0.4565 - acc: 0.8919\n",
      "Epoch 131/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.5295 - acc: 0.8604\n",
      "Epoch 132/700\n",
      "222/222 [==============================] - 0s 121us/step - loss: 0.4955 - acc: 0.8919\n",
      "Epoch 133/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.4904 - acc: 0.8829\n",
      "Epoch 134/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.4307 - acc: 0.9009\n",
      "Epoch 135/700\n",
      "222/222 [==============================] - 0s 116us/step - loss: 0.4118 - acc: 0.9144\n",
      "Epoch 136/700\n",
      "222/222 [==============================] - 0s 104us/step - loss: 0.5104 - acc: 0.8919\n",
      "Epoch 137/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.4348 - acc: 0.8964\n",
      "Epoch 138/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.4270 - acc: 0.9099\n",
      "Epoch 139/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.5378 - acc: 0.8784\n",
      "Epoch 140/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.5119 - acc: 0.8739\n",
      "Epoch 141/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.5581 - acc: 0.8604\n",
      "Epoch 142/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.4018 - acc: 0.8964\n",
      "Epoch 143/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.5220 - acc: 0.8874\n",
      "Epoch 144/700\n",
      "222/222 [==============================] - 0s 115us/step - loss: 0.5330 - acc: 0.8919\n",
      "Epoch 145/700\n",
      "222/222 [==============================] - 0s 116us/step - loss: 0.4791 - acc: 0.9009\n",
      "Epoch 146/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.3719 - acc: 0.9459\n",
      "Epoch 147/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.3714 - acc: 0.9234\n",
      "Epoch 148/700\n",
      "222/222 [==============================] - 0s 103us/step - loss: 0.5375 - acc: 0.8694\n",
      "Epoch 149/700\n",
      "222/222 [==============================] - 0s 117us/step - loss: 0.5436 - acc: 0.9054\n",
      "Epoch 150/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 0.5058 - acc: 0.8874\n",
      "Epoch 151/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.4998 - acc: 0.8874\n",
      "Epoch 152/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.4682 - acc: 0.9009\n",
      "Epoch 153/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.4053 - acc: 0.9144\n",
      "Epoch 154/700\n",
      "222/222 [==============================] - 0s 104us/step - loss: 0.4002 - acc: 0.9234\n",
      "Epoch 155/700\n",
      "222/222 [==============================] - 0s 116us/step - loss: 0.5354 - acc: 0.8559\n",
      "Epoch 156/700\n",
      "222/222 [==============================] - 0s 104us/step - loss: 0.3562 - acc: 0.9324\n",
      "Epoch 157/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222/222 [==============================] - 0s 117us/step - loss: 0.4706 - acc: 0.9144\n",
      "Epoch 158/700\n",
      "222/222 [==============================] - 0s 105us/step - loss: 0.4094 - acc: 0.8874\n",
      "Epoch 159/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.5418 - acc: 0.8829\n",
      "Epoch 160/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.3607 - acc: 0.9459\n",
      "Epoch 161/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.3784 - acc: 0.9144\n",
      "Epoch 162/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.3215 - acc: 0.9279\n",
      "Epoch 163/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.3448 - acc: 0.9369\n",
      "Epoch 164/700\n",
      "222/222 [==============================] - 0s 116us/step - loss: 0.4153 - acc: 0.9234\n",
      "Epoch 165/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 0.3921 - acc: 0.9054\n",
      "Epoch 166/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.3344 - acc: 0.9324\n",
      "Epoch 167/700\n",
      "222/222 [==============================] - 0s 103us/step - loss: 0.3894 - acc: 0.9279\n",
      "Epoch 168/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.4274 - acc: 0.9234\n",
      "Epoch 169/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.3447 - acc: 0.9279\n",
      "Epoch 170/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.4839 - acc: 0.8964\n",
      "Epoch 171/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.3350 - acc: 0.9505\n",
      "Epoch 172/700\n",
      "222/222 [==============================] - 0s 116us/step - loss: 0.3062 - acc: 0.9550\n",
      "Epoch 173/700\n",
      "222/222 [==============================] - 0s 117us/step - loss: 0.4314 - acc: 0.8964\n",
      "Epoch 174/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.3469 - acc: 0.9324\n",
      "Epoch 175/700\n",
      "222/222 [==============================] - 0s 115us/step - loss: 0.3917 - acc: 0.8919\n",
      "Epoch 176/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.4019 - acc: 0.9009\n",
      "Epoch 177/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.3627 - acc: 0.9279\n",
      "Epoch 178/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.4373 - acc: 0.8964\n",
      "Epoch 179/700\n",
      "222/222 [==============================] - 0s 117us/step - loss: 0.4690 - acc: 0.9189\n",
      "Epoch 180/700\n",
      "222/222 [==============================] - 0s 116us/step - loss: 0.4517 - acc: 0.9099\n",
      "Epoch 181/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.4114 - acc: 0.9189\n",
      "Epoch 182/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.4239 - acc: 0.9189\n",
      "Epoch 183/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.5055 - acc: 0.8919\n",
      "Epoch 184/700\n",
      "222/222 [==============================] - 0s 103us/step - loss: 0.4080 - acc: 0.9234\n",
      "Epoch 185/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.4467 - acc: 0.9099\n",
      "Epoch 186/700\n",
      "222/222 [==============================] - 0s 105us/step - loss: 0.4333 - acc: 0.9234\n",
      "Epoch 187/700\n",
      "222/222 [==============================] - 0s 119us/step - loss: 0.3968 - acc: 0.9324\n",
      "Epoch 188/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.4262 - acc: 0.9279\n",
      "Epoch 189/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.3586 - acc: 0.9414\n",
      "Epoch 190/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.3873 - acc: 0.9279\n",
      "Epoch 191/700\n",
      "222/222 [==============================] - 0s 116us/step - loss: 0.3539 - acc: 0.9279\n",
      "Epoch 192/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.5342 - acc: 0.9009\n",
      "Epoch 193/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.2778 - acc: 0.9595\n",
      "Epoch 194/700\n",
      "222/222 [==============================] - 0s 123us/step - loss: 0.4182 - acc: 0.9099\n",
      "Epoch 195/700\n",
      "222/222 [==============================] - 0s 116us/step - loss: 0.3455 - acc: 0.9414\n",
      "Epoch 196/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.4612 - acc: 0.8919\n",
      "Epoch 197/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.3274 - acc: 0.9324\n",
      "Epoch 198/700\n",
      "222/222 [==============================] - 0s 118us/step - loss: 0.4187 - acc: 0.8964\n",
      "Epoch 199/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.5179 - acc: 0.8919\n",
      "Epoch 200/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.3833 - acc: 0.9054\n",
      "Epoch 201/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.3345 - acc: 0.9505\n",
      "Epoch 202/700\n",
      "222/222 [==============================] - 0s 115us/step - loss: 0.4124 - acc: 0.9369\n",
      "Epoch 203/700\n",
      "222/222 [==============================] - 0s 115us/step - loss: 0.4138 - acc: 0.9144\n",
      "Epoch 204/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.3918 - acc: 0.9459\n",
      "Epoch 205/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.4085 - acc: 0.9054\n",
      "Epoch 206/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.3381 - acc: 0.9414\n",
      "Epoch 207/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.3618 - acc: 0.9324\n",
      "Epoch 208/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.4184 - acc: 0.9144\n",
      "Epoch 209/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.3517 - acc: 0.9369\n",
      "Epoch 210/700\n",
      "222/222 [==============================] - 0s 116us/step - loss: 0.4447 - acc: 0.9279\n",
      "Epoch 211/700\n",
      "222/222 [==============================] - 0s 115us/step - loss: 0.3422 - acc: 0.9324\n",
      "Epoch 212/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 0.4844 - acc: 0.9279\n",
      "Epoch 213/700\n",
      "222/222 [==============================] - 0s 116us/step - loss: 0.3443 - acc: 0.9505\n",
      "Epoch 214/700\n",
      "222/222 [==============================] - 0s 130us/step - loss: 0.4743 - acc: 0.8964\n",
      "Epoch 215/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.2432 - acc: 0.9685\n",
      "Epoch 216/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.3482 - acc: 0.9369\n",
      "Epoch 217/700\n",
      "222/222 [==============================] - 0s 102us/step - loss: 0.3156 - acc: 0.9459\n",
      "Epoch 218/700\n",
      "222/222 [==============================] - 0s 123us/step - loss: 0.3791 - acc: 0.9234\n",
      "Epoch 219/700\n",
      "222/222 [==============================] - 0s 102us/step - loss: 0.3215 - acc: 0.9369\n",
      "Epoch 220/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.3570 - acc: 0.9369\n",
      "Epoch 221/700\n",
      "222/222 [==============================] - 0s 101us/step - loss: 0.3895 - acc: 0.9144\n",
      "Epoch 222/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.4012 - acc: 0.9279\n",
      "Epoch 223/700\n",
      "222/222 [==============================] - 0s 104us/step - loss: 0.2586 - acc: 0.9505\n",
      "Epoch 224/700\n",
      "222/222 [==============================] - 0s 127us/step - loss: 0.3533 - acc: 0.9234\n",
      "Epoch 225/700\n",
      "222/222 [==============================] - 0s 105us/step - loss: 0.3671 - acc: 0.9279\n",
      "Epoch 226/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.3685 - acc: 0.9324\n",
      "Epoch 227/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.3707 - acc: 0.9189\n",
      "Epoch 228/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.4731 - acc: 0.8874\n",
      "Epoch 229/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.3701 - acc: 0.9279\n",
      "Epoch 230/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.4041 - acc: 0.9144\n",
      "Epoch 231/700\n",
      "222/222 [==============================] - 0s 117us/step - loss: 0.3625 - acc: 0.9324\n",
      "Epoch 232/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.3570 - acc: 0.9369\n",
      "Epoch 233/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.2735 - acc: 0.9459\n",
      "Epoch 234/700\n",
      "222/222 [==============================] - 0s 116us/step - loss: 0.3759 - acc: 0.9189\n",
      "Epoch 235/700\n",
      "222/222 [==============================] - 0s 119us/step - loss: 0.2389 - acc: 0.9640\n",
      "Epoch 236/700\n",
      "222/222 [==============================] - 0s 117us/step - loss: 0.3332 - acc: 0.9279\n",
      "Epoch 237/700\n",
      "222/222 [==============================] - 0s 124us/step - loss: 0.3402 - acc: 0.9414\n",
      "Epoch 238/700\n",
      "222/222 [==============================] - 0s 121us/step - loss: 0.2704 - acc: 0.9595\n",
      "Epoch 239/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222/222 [==============================] - 0s 122us/step - loss: 0.3241 - acc: 0.9459\n",
      "Epoch 240/700\n",
      "222/222 [==============================] - 0s 116us/step - loss: 0.3702 - acc: 0.9279\n",
      "Epoch 241/700\n",
      "222/222 [==============================] - 0s 115us/step - loss: 0.2930 - acc: 0.9414\n",
      "Epoch 242/700\n",
      "222/222 [==============================] - 0s 115us/step - loss: 0.3700 - acc: 0.9414\n",
      "Epoch 243/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.2970 - acc: 0.9505\n",
      "Epoch 244/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.2721 - acc: 0.9279\n",
      "Epoch 245/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.3902 - acc: 0.9459\n",
      "Epoch 246/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.3638 - acc: 0.9324\n",
      "Epoch 247/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.2697 - acc: 0.9459\n",
      "Epoch 248/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.3549 - acc: 0.9279\n",
      "Epoch 249/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.2729 - acc: 0.9640\n",
      "Epoch 250/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.3374 - acc: 0.9144\n",
      "Epoch 251/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.2769 - acc: 0.9505\n",
      "Epoch 252/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.3836 - acc: 0.9324\n",
      "Epoch 253/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.2621 - acc: 0.9640\n",
      "Epoch 254/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.3126 - acc: 0.9459\n",
      "Epoch 255/700\n",
      "222/222 [==============================] - 0s 118us/step - loss: 0.2804 - acc: 0.9414\n",
      "Epoch 256/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.3498 - acc: 0.9099\n",
      "Epoch 257/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.3399 - acc: 0.9234\n",
      "Epoch 258/700\n",
      "222/222 [==============================] - 0s 119us/step - loss: 0.3690 - acc: 0.9234\n",
      "Epoch 259/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.3691 - acc: 0.9324\n",
      "Epoch 260/700\n",
      "222/222 [==============================] - 0s 118us/step - loss: 0.3347 - acc: 0.9279\n",
      "Epoch 261/700\n",
      "222/222 [==============================] - 0s 115us/step - loss: 0.2558 - acc: 0.9550\n",
      "Epoch 262/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.4011 - acc: 0.9324\n",
      "Epoch 263/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.2853 - acc: 0.9505\n",
      "Epoch 264/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.3186 - acc: 0.9324\n",
      "Epoch 265/700\n",
      "222/222 [==============================] - 0s 115us/step - loss: 0.3076 - acc: 0.9414\n",
      "Epoch 266/700\n",
      "222/222 [==============================] - 0s 119us/step - loss: 0.2274 - acc: 0.9595\n",
      "Epoch 267/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.2712 - acc: 0.9550\n",
      "Epoch 268/700\n",
      "222/222 [==============================] - 0s 118us/step - loss: 0.4033 - acc: 0.9279\n",
      "Epoch 269/700\n",
      "222/222 [==============================] - 0s 120us/step - loss: 0.3242 - acc: 0.9189\n",
      "Epoch 270/700\n",
      "222/222 [==============================] - 0s 120us/step - loss: 0.3753 - acc: 0.9279\n",
      "Epoch 271/700\n",
      "222/222 [==============================] - 0s 116us/step - loss: 0.3020 - acc: 0.9324\n",
      "Epoch 272/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.2304 - acc: 0.9595\n",
      "Epoch 273/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.3066 - acc: 0.9279\n",
      "Epoch 274/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 0.2957 - acc: 0.9459\n",
      "Epoch 275/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.3160 - acc: 0.9414\n",
      "Epoch 276/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.2936 - acc: 0.9550\n",
      "Epoch 277/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.2375 - acc: 0.9505\n",
      "Epoch 278/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.2840 - acc: 0.9459\n",
      "Epoch 279/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.3563 - acc: 0.9234\n",
      "Epoch 280/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.3719 - acc: 0.9234\n",
      "Epoch 281/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.3015 - acc: 0.9459\n",
      "Epoch 282/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.3186 - acc: 0.9369\n",
      "Epoch 283/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.2471 - acc: 0.9685\n",
      "Epoch 284/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.4645 - acc: 0.9189\n",
      "Epoch 285/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.2410 - acc: 0.9640\n",
      "Epoch 286/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.2323 - acc: 0.9505\n",
      "Epoch 287/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.2523 - acc: 0.9685\n",
      "Epoch 288/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.3077 - acc: 0.9324\n",
      "Epoch 289/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.2459 - acc: 0.9369\n",
      "Epoch 290/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.2169 - acc: 0.9730\n",
      "Epoch 291/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.2909 - acc: 0.9459\n",
      "Epoch 292/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.2154 - acc: 0.9550\n",
      "Epoch 293/700\n",
      "222/222 [==============================] - 0s 115us/step - loss: 0.2798 - acc: 0.9414\n",
      "Epoch 294/700\n",
      "222/222 [==============================] - 0s 115us/step - loss: 0.3660 - acc: 0.9189\n",
      "Epoch 295/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.2428 - acc: 0.9550\n",
      "Epoch 296/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.2597 - acc: 0.9595\n",
      "Epoch 297/700\n",
      "222/222 [==============================] - 0s 117us/step - loss: 0.2718 - acc: 0.9505\n",
      "Epoch 298/700\n",
      "222/222 [==============================] - 0s 116us/step - loss: 0.2378 - acc: 0.9505\n",
      "Epoch 299/700\n",
      "222/222 [==============================] - 0s 115us/step - loss: 0.4155 - acc: 0.8964\n",
      "Epoch 300/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.3239 - acc: 0.9189\n",
      "Epoch 301/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.3247 - acc: 0.9459\n",
      "Epoch 302/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.1727 - acc: 0.9595\n",
      "Epoch 303/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.2283 - acc: 0.9595\n",
      "Epoch 304/700\n",
      "222/222 [==============================] - 0s 117us/step - loss: 0.2595 - acc: 0.9640\n",
      "Epoch 305/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.3371 - acc: 0.9324\n",
      "Epoch 306/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.3328 - acc: 0.9414\n",
      "Epoch 307/700\n",
      "222/222 [==============================] - 0s 104us/step - loss: 0.2403 - acc: 0.9595\n",
      "Epoch 308/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.2697 - acc: 0.9369\n",
      "Epoch 309/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.2315 - acc: 0.9595\n",
      "Epoch 310/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.2402 - acc: 0.9550\n",
      "Epoch 311/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.2955 - acc: 0.9505\n",
      "Epoch 312/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.2310 - acc: 0.9550\n",
      "Epoch 313/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.2183 - acc: 0.9640\n",
      "Epoch 314/700\n",
      "222/222 [==============================] - 0s 115us/step - loss: 0.2594 - acc: 0.9550\n",
      "Epoch 315/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.1998 - acc: 0.9505\n",
      "Epoch 316/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.1962 - acc: 0.9640\n",
      "Epoch 317/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.2883 - acc: 0.9414\n",
      "Epoch 318/700\n",
      "222/222 [==============================] - 0s 118us/step - loss: 0.2199 - acc: 0.9640\n",
      "Epoch 319/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.2788 - acc: 0.9414\n",
      "Epoch 320/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.2803 - acc: 0.9414\n",
      "Epoch 321/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222/222 [==============================] - 0s 105us/step - loss: 0.2438 - acc: 0.9189\n",
      "Epoch 322/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.1990 - acc: 0.9550\n",
      "Epoch 323/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.2526 - acc: 0.9459\n",
      "Epoch 324/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 0.2707 - acc: 0.9459\n",
      "Epoch 325/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.3057 - acc: 0.9459\n",
      "Epoch 326/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 0.3250 - acc: 0.9144\n",
      "Epoch 327/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.1930 - acc: 0.9595\n",
      "Epoch 328/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.2089 - acc: 0.9595\n",
      "Epoch 329/700\n",
      "222/222 [==============================] - 0s 117us/step - loss: 0.2795 - acc: 0.9369\n",
      "Epoch 330/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.2296 - acc: 0.9640\n",
      "Epoch 331/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.2313 - acc: 0.9550\n",
      "Epoch 332/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.2999 - acc: 0.9234\n",
      "Epoch 333/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.2919 - acc: 0.9550\n",
      "Epoch 334/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.3534 - acc: 0.9054\n",
      "Epoch 335/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.1770 - acc: 0.9595\n",
      "Epoch 336/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.1907 - acc: 0.9595\n",
      "Epoch 337/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.2879 - acc: 0.9505\n",
      "Epoch 338/700\n",
      "222/222 [==============================] - 0s 118us/step - loss: 0.2097 - acc: 0.9595\n",
      "Epoch 339/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.2000 - acc: 0.9595\n",
      "Epoch 340/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.2235 - acc: 0.9640\n",
      "Epoch 341/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.2186 - acc: 0.9550\n",
      "Epoch 342/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.2394 - acc: 0.9414\n",
      "Epoch 343/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.2898 - acc: 0.9234\n",
      "Epoch 344/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.1900 - acc: 0.9775\n",
      "Epoch 345/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.1743 - acc: 0.9595\n",
      "Epoch 346/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.2239 - acc: 0.9505\n",
      "Epoch 347/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.1577 - acc: 0.9730\n",
      "Epoch 348/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.2221 - acc: 0.9640\n",
      "Epoch 349/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 0.2041 - acc: 0.9550\n",
      "Epoch 350/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.2240 - acc: 0.9459\n",
      "Epoch 351/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.2110 - acc: 0.9640\n",
      "Epoch 352/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.1994 - acc: 0.9640\n",
      "Epoch 353/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.1370 - acc: 0.9820\n",
      "Epoch 354/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.2485 - acc: 0.9459\n",
      "Epoch 355/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.2796 - acc: 0.9505\n",
      "Epoch 356/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.2661 - acc: 0.9550\n",
      "Epoch 357/700\n",
      "222/222 [==============================] - 0s 105us/step - loss: 0.2254 - acc: 0.9595\n",
      "Epoch 358/700\n",
      "222/222 [==============================] - 0s 115us/step - loss: 0.1661 - acc: 0.9775\n",
      "Epoch 359/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.2469 - acc: 0.9505\n",
      "Epoch 360/700\n",
      "222/222 [==============================] - 0s 118us/step - loss: 0.1685 - acc: 0.9730\n",
      "Epoch 361/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.2330 - acc: 0.9550\n",
      "Epoch 362/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.1677 - acc: 0.9640\n",
      "Epoch 363/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.1818 - acc: 0.9685\n",
      "Epoch 364/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.2439 - acc: 0.9414\n",
      "Epoch 365/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 0.2287 - acc: 0.9414\n",
      "Epoch 366/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.1757 - acc: 0.9820\n",
      "Epoch 367/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.1782 - acc: 0.9685\n",
      "Epoch 368/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.1996 - acc: 0.9730\n",
      "Epoch 369/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.2595 - acc: 0.9414\n",
      "Epoch 370/700\n",
      "222/222 [==============================] - 0s 115us/step - loss: 0.2186 - acc: 0.9550\n",
      "Epoch 371/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.2257 - acc: 0.9550\n",
      "Epoch 372/700\n",
      "222/222 [==============================] - 0s 104us/step - loss: 0.1686 - acc: 0.9640\n",
      "Epoch 373/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.1985 - acc: 0.9505\n",
      "Epoch 374/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.2477 - acc: 0.9505\n",
      "Epoch 375/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.1213 - acc: 0.9820\n",
      "Epoch 376/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.1887 - acc: 0.9640\n",
      "Epoch 377/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.1561 - acc: 0.9640\n",
      "Epoch 378/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.2487 - acc: 0.9459\n",
      "Epoch 379/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.1196 - acc: 0.9640\n",
      "Epoch 380/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.2100 - acc: 0.9550\n",
      "Epoch 381/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.1696 - acc: 0.9685\n",
      "Epoch 382/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.2094 - acc: 0.9550\n",
      "Epoch 383/700\n",
      "222/222 [==============================] - 0s 127us/step - loss: 0.1498 - acc: 0.9775\n",
      "Epoch 384/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.1733 - acc: 0.9595\n",
      "Epoch 385/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.1906 - acc: 0.9640\n",
      "Epoch 386/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.1604 - acc: 0.9775\n",
      "Epoch 387/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.1761 - acc: 0.9685\n",
      "Epoch 388/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.1334 - acc: 0.9775\n",
      "Epoch 389/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.2726 - acc: 0.9324\n",
      "Epoch 390/700\n",
      "222/222 [==============================] - 0s 104us/step - loss: 0.1867 - acc: 0.9640\n",
      "Epoch 391/700\n",
      "222/222 [==============================] - 0s 116us/step - loss: 0.2248 - acc: 0.9459\n",
      "Epoch 392/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.1662 - acc: 0.9640\n",
      "Epoch 393/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.1060 - acc: 0.9955\n",
      "Epoch 394/700\n",
      "222/222 [==============================] - 0s 105us/step - loss: 0.1904 - acc: 0.9550\n",
      "Epoch 395/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.1683 - acc: 0.9595\n",
      "Epoch 396/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.1518 - acc: 0.9685\n",
      "Epoch 397/700\n",
      "222/222 [==============================] - 0s 116us/step - loss: 0.1807 - acc: 0.9640\n",
      "Epoch 398/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 0.1707 - acc: 0.9550\n",
      "Epoch 399/700\n",
      "222/222 [==============================] - 0s 117us/step - loss: 0.1896 - acc: 0.9595\n",
      "Epoch 400/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.1634 - acc: 0.9595\n",
      "Epoch 401/700\n",
      "222/222 [==============================] - 0s 137us/step - loss: 0.1680 - acc: 0.9505\n",
      "Epoch 402/700\n",
      "222/222 [==============================] - 0s 156us/step - loss: 0.2041 - acc: 0.9595\n",
      "Epoch 403/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222/222 [==============================] - 0s 148us/step - loss: 0.1406 - acc: 0.9730\n",
      "Epoch 404/700\n",
      "222/222 [==============================] - 0s 137us/step - loss: 0.1376 - acc: 0.9640\n",
      "Epoch 405/700\n",
      "222/222 [==============================] - 0s 117us/step - loss: 0.1963 - acc: 0.9595\n",
      "Epoch 406/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.1972 - acc: 0.9595\n",
      "Epoch 407/700\n",
      "222/222 [==============================] - 0s 105us/step - loss: 0.1473 - acc: 0.9730\n",
      "Epoch 408/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.1702 - acc: 0.9640\n",
      "Epoch 409/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 0.1885 - acc: 0.9595\n",
      "Epoch 410/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.1325 - acc: 0.9775\n",
      "Epoch 411/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.1229 - acc: 0.9730\n",
      "Epoch 412/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.1753 - acc: 0.9640\n",
      "Epoch 413/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.1443 - acc: 0.9775\n",
      "Epoch 414/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.1509 - acc: 0.9685\n",
      "Epoch 415/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.2071 - acc: 0.9414\n",
      "Epoch 416/700\n",
      "222/222 [==============================] - 0s 115us/step - loss: 0.1817 - acc: 0.9595\n",
      "Epoch 417/700\n",
      "222/222 [==============================] - 0s 105us/step - loss: 0.1653 - acc: 0.9550\n",
      "Epoch 418/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.1763 - acc: 0.9595\n",
      "Epoch 419/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.1751 - acc: 0.9730\n",
      "Epoch 420/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.1382 - acc: 0.9685\n",
      "Epoch 421/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.1388 - acc: 0.9685\n",
      "Epoch 422/700\n",
      "222/222 [==============================] - 0s 115us/step - loss: 0.1617 - acc: 0.9640\n",
      "Epoch 423/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.1635 - acc: 0.9685\n",
      "Epoch 424/700\n",
      "222/222 [==============================] - 0s 116us/step - loss: 0.1323 - acc: 0.9730\n",
      "Epoch 425/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.2160 - acc: 0.9459\n",
      "Epoch 426/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.1986 - acc: 0.9685\n",
      "Epoch 427/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.1545 - acc: 0.9730\n",
      "Epoch 428/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.1673 - acc: 0.9685\n",
      "Epoch 429/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.1052 - acc: 0.9865\n",
      "Epoch 430/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.2212 - acc: 0.9459\n",
      "Epoch 431/700\n",
      "222/222 [==============================] - 0s 104us/step - loss: 0.1387 - acc: 0.9685\n",
      "Epoch 432/700\n",
      "222/222 [==============================] - 0s 115us/step - loss: 0.1630 - acc: 0.9775\n",
      "Epoch 433/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.1531 - acc: 0.9640\n",
      "Epoch 434/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.1360 - acc: 0.9595\n",
      "Epoch 435/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.1610 - acc: 0.9820\n",
      "Epoch 436/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.1992 - acc: 0.9414\n",
      "Epoch 437/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.1787 - acc: 0.9505\n",
      "Epoch 438/700\n",
      "222/222 [==============================] - 0s 115us/step - loss: 0.1303 - acc: 0.9820\n",
      "Epoch 439/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.1546 - acc: 0.9730\n",
      "Epoch 440/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.1907 - acc: 0.9505\n",
      "Epoch 441/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.1281 - acc: 0.9730\n",
      "Epoch 442/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.2104 - acc: 0.9369\n",
      "Epoch 443/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.1175 - acc: 0.9775\n",
      "Epoch 444/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.1274 - acc: 0.9730\n",
      "Epoch 445/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.1895 - acc: 0.9505\n",
      "Epoch 446/700\n",
      "222/222 [==============================] - 0s 119us/step - loss: 0.1405 - acc: 0.9730\n",
      "Epoch 447/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.1641 - acc: 0.9595\n",
      "Epoch 448/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.1504 - acc: 0.9775\n",
      "Epoch 449/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.0822 - acc: 0.9910\n",
      "Epoch 450/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.1670 - acc: 0.9595\n",
      "Epoch 451/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.1269 - acc: 0.9730\n",
      "Epoch 452/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.0922 - acc: 0.9865\n",
      "Epoch 453/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.1648 - acc: 0.9550\n",
      "Epoch 454/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.1460 - acc: 0.9685\n",
      "Epoch 455/700\n",
      "222/222 [==============================] - 0s 117us/step - loss: 0.1639 - acc: 0.9640\n",
      "Epoch 456/700\n",
      "222/222 [==============================] - 0s 104us/step - loss: 0.1204 - acc: 0.9730\n",
      "Epoch 457/700\n",
      "222/222 [==============================] - 0s 118us/step - loss: 0.1329 - acc: 0.9640\n",
      "Epoch 458/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 0.1464 - acc: 0.9640\n",
      "Epoch 459/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.1022 - acc: 0.9865\n",
      "Epoch 460/700\n",
      "222/222 [==============================] - 0s 105us/step - loss: 0.1894 - acc: 0.9685\n",
      "Epoch 461/700\n",
      "222/222 [==============================] - 0s 116us/step - loss: 0.1373 - acc: 0.9550\n",
      "Epoch 462/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.0898 - acc: 0.9865\n",
      "Epoch 463/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.1303 - acc: 0.9730\n",
      "Epoch 464/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.1420 - acc: 0.9730\n",
      "Epoch 465/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.1343 - acc: 0.9730\n",
      "Epoch 466/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 0.1030 - acc: 0.9685\n",
      "Epoch 467/700\n",
      "222/222 [==============================] - 0s 124us/step - loss: 0.1082 - acc: 0.9730\n",
      "Epoch 468/700\n",
      "222/222 [==============================] - 0s 117us/step - loss: 0.1075 - acc: 0.9775\n",
      "Epoch 469/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 0.1468 - acc: 0.9550\n",
      "Epoch 470/700\n",
      "222/222 [==============================] - 0s 118us/step - loss: 0.1323 - acc: 0.9685\n",
      "Epoch 471/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.1620 - acc: 0.9640\n",
      "Epoch 472/700\n",
      "222/222 [==============================] - 0s 116us/step - loss: 0.1038 - acc: 0.9685\n",
      "Epoch 473/700\n",
      "222/222 [==============================] - 0s 105us/step - loss: 0.1913 - acc: 0.9505\n",
      "Epoch 474/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.1963 - acc: 0.9505\n",
      "Epoch 475/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.1186 - acc: 0.9730\n",
      "Epoch 476/700\n",
      "222/222 [==============================] - 0s 122us/step - loss: 0.1670 - acc: 0.9505\n",
      "Epoch 477/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 0.1309 - acc: 0.9730\n",
      "Epoch 478/700\n",
      "222/222 [==============================] - 0s 105us/step - loss: 0.1388 - acc: 0.9775\n",
      "Epoch 479/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.1170 - acc: 0.9640\n",
      "Epoch 480/700\n",
      "222/222 [==============================] - 0s 104us/step - loss: 0.1119 - acc: 0.9775\n",
      "Epoch 481/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.1649 - acc: 0.9640\n",
      "Epoch 482/700\n",
      "222/222 [==============================] - 0s 131us/step - loss: 0.1538 - acc: 0.9595\n",
      "Epoch 483/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.1665 - acc: 0.9550\n",
      "Epoch 484/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.1360 - acc: 0.9640\n",
      "Epoch 485/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222/222 [==============================] - 0s 105us/step - loss: 0.1009 - acc: 0.9775\n",
      "Epoch 486/700\n",
      "222/222 [==============================] - 0s 103us/step - loss: 0.1078 - acc: 0.9730\n",
      "Epoch 487/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 0.1548 - acc: 0.9595\n",
      "Epoch 488/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 0.0925 - acc: 0.9820\n",
      "Epoch 489/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.1236 - acc: 0.9730\n",
      "Epoch 490/700\n",
      "222/222 [==============================] - 0s 104us/step - loss: 0.1668 - acc: 0.9595\n",
      "Epoch 491/700\n",
      "222/222 [==============================] - 0s 104us/step - loss: 0.1129 - acc: 0.9730\n",
      "Epoch 492/700\n",
      "222/222 [==============================] - 0s 104us/step - loss: 0.0906 - acc: 0.9775\n",
      "Epoch 493/700\n",
      "222/222 [==============================] - 0s 102us/step - loss: 0.1762 - acc: 0.9550\n",
      "Epoch 494/700\n",
      "222/222 [==============================] - 0s 102us/step - loss: 0.0674 - acc: 0.9910\n",
      "Epoch 495/700\n",
      "222/222 [==============================] - 0s 98us/step - loss: 0.1212 - acc: 0.9730\n",
      "Epoch 496/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.1520 - acc: 0.9550\n",
      "Epoch 497/700\n",
      "222/222 [==============================] - 0s 101us/step - loss: 0.0959 - acc: 0.9775\n",
      "Epoch 498/700\n",
      "222/222 [==============================] - 0s 100us/step - loss: 0.1680 - acc: 0.9595\n",
      "Epoch 499/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 0.1514 - acc: 0.9730\n",
      "Epoch 500/700\n",
      "222/222 [==============================] - 0s 99us/step - loss: 0.1517 - acc: 0.9640\n",
      "Epoch 501/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.1417 - acc: 0.9685\n",
      "Epoch 502/700\n",
      "222/222 [==============================] - 0s 100us/step - loss: 0.2104 - acc: 0.9505\n",
      "Epoch 503/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.0929 - acc: 0.9820\n",
      "Epoch 504/700\n",
      "222/222 [==============================] - 0s 105us/step - loss: 0.0871 - acc: 0.9820\n",
      "Epoch 505/700\n",
      "222/222 [==============================] - 0s 105us/step - loss: 0.0914 - acc: 0.9775\n",
      "Epoch 506/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.1002 - acc: 0.9730\n",
      "Epoch 507/700\n",
      "222/222 [==============================] - 0s 104us/step - loss: 0.1736 - acc: 0.9505\n",
      "Epoch 508/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.1013 - acc: 0.9820\n",
      "Epoch 509/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 0.1270 - acc: 0.9730\n",
      "Epoch 510/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.0903 - acc: 0.9730\n",
      "Epoch 511/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.1495 - acc: 0.9685\n",
      "Epoch 512/700\n",
      "222/222 [==============================] - 0s 118us/step - loss: 0.1158 - acc: 0.9820\n",
      "Epoch 513/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.0963 - acc: 0.9820\n",
      "Epoch 514/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.1357 - acc: 0.9550\n",
      "Epoch 515/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.0904 - acc: 0.9775\n",
      "Epoch 516/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.1275 - acc: 0.9775\n",
      "Epoch 517/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.0599 - acc: 0.9910\n",
      "Epoch 518/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.1369 - acc: 0.9550\n",
      "Epoch 519/700\n",
      "222/222 [==============================] - 0s 117us/step - loss: 0.1296 - acc: 0.9595\n",
      "Epoch 520/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.1225 - acc: 0.9730\n",
      "Epoch 521/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.1154 - acc: 0.9685\n",
      "Epoch 522/700\n",
      "222/222 [==============================] - 0s 116us/step - loss: 0.1063 - acc: 0.9685\n",
      "Epoch 523/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.1262 - acc: 0.9685\n",
      "Epoch 524/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.1047 - acc: 0.9775\n",
      "Epoch 525/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.1289 - acc: 0.9595\n",
      "Epoch 526/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.1187 - acc: 0.9775\n",
      "Epoch 527/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 0.1178 - acc: 0.9640\n",
      "Epoch 528/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.0983 - acc: 0.9820\n",
      "Epoch 529/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.1226 - acc: 0.9640\n",
      "Epoch 530/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.0320 - acc: 1.0000\n",
      "Epoch 531/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.1157 - acc: 0.9685\n",
      "Epoch 532/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.1295 - acc: 0.9640\n",
      "Epoch 533/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.1107 - acc: 0.9775\n",
      "Epoch 534/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.1290 - acc: 0.9640\n",
      "Epoch 535/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.0956 - acc: 0.9775\n",
      "Epoch 536/700\n",
      "222/222 [==============================] - 0s 116us/step - loss: 0.0951 - acc: 0.9730\n",
      "Epoch 537/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.1088 - acc: 0.9730\n",
      "Epoch 538/700\n",
      "222/222 [==============================] - 0s 116us/step - loss: 0.0697 - acc: 0.9775\n",
      "Epoch 539/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.1649 - acc: 0.9640\n",
      "Epoch 540/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.0862 - acc: 0.9820\n",
      "Epoch 541/700\n",
      "222/222 [==============================] - 0s 115us/step - loss: 0.1262 - acc: 0.9640\n",
      "Epoch 542/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.0892 - acc: 0.9730\n",
      "Epoch 543/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.1061 - acc: 0.9640\n",
      "Epoch 544/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.1769 - acc: 0.9414\n",
      "Epoch 545/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.1458 - acc: 0.9595\n",
      "Epoch 546/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.0717 - acc: 0.9820\n",
      "Epoch 547/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.1964 - acc: 0.9505\n",
      "Epoch 548/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.0993 - acc: 0.9865\n",
      "Epoch 549/700\n",
      "222/222 [==============================] - 0s 104us/step - loss: 0.1212 - acc: 0.9685\n",
      "Epoch 550/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.0724 - acc: 0.9865\n",
      "Epoch 551/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.1093 - acc: 0.9775\n",
      "Epoch 552/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.1180 - acc: 0.9730\n",
      "Epoch 553/700\n",
      "222/222 [==============================] - 0s 116us/step - loss: 0.1495 - acc: 0.9640\n",
      "Epoch 554/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.1146 - acc: 0.9595\n",
      "Epoch 555/700\n",
      "222/222 [==============================] - 0s 120us/step - loss: 0.1092 - acc: 0.9775\n",
      "Epoch 556/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.1092 - acc: 0.9730\n",
      "Epoch 557/700\n",
      "222/222 [==============================] - 0s 115us/step - loss: 0.1407 - acc: 0.9550\n",
      "Epoch 558/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.1086 - acc: 0.9775\n",
      "Epoch 559/700\n",
      "222/222 [==============================] - 0s 122us/step - loss: 0.0891 - acc: 0.9820\n",
      "Epoch 560/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.1214 - acc: 0.9595\n",
      "Epoch 561/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.0846 - acc: 0.9820\n",
      "Epoch 562/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.0821 - acc: 0.9865\n",
      "Epoch 563/700\n",
      "222/222 [==============================] - 0s 120us/step - loss: 0.0885 - acc: 0.9820\n",
      "Epoch 564/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.0693 - acc: 0.9865\n",
      "Epoch 565/700\n",
      "222/222 [==============================] - 0s 105us/step - loss: 0.0421 - acc: 0.9955\n",
      "Epoch 566/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.1061 - acc: 0.9730\n",
      "Epoch 567/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222/222 [==============================] - 0s 111us/step - loss: 0.1169 - acc: 0.9685\n",
      "Epoch 568/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 0.0519 - acc: 0.9910\n",
      "Epoch 569/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.1300 - acc: 0.9685\n",
      "Epoch 570/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.0988 - acc: 0.9820\n",
      "Epoch 571/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.1236 - acc: 0.9685\n",
      "Epoch 572/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.1192 - acc: 0.9685\n",
      "Epoch 573/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.1053 - acc: 0.9685\n",
      "Epoch 574/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.0807 - acc: 0.9775\n",
      "Epoch 575/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.0906 - acc: 0.9730\n",
      "Epoch 576/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.0997 - acc: 0.9730\n",
      "Epoch 577/700\n",
      "222/222 [==============================] - 0s 105us/step - loss: 0.1160 - acc: 0.9685\n",
      "Epoch 578/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.0889 - acc: 0.9865\n",
      "Epoch 579/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.1126 - acc: 0.9730\n",
      "Epoch 580/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.1426 - acc: 0.9550\n",
      "Epoch 581/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.0713 - acc: 0.9820\n",
      "Epoch 582/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.0378 - acc: 0.9910\n",
      "Epoch 583/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.0939 - acc: 0.9775\n",
      "Epoch 584/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.0983 - acc: 0.9820\n",
      "Epoch 585/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.1605 - acc: 0.9550\n",
      "Epoch 586/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.0712 - acc: 0.9820\n",
      "Epoch 587/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.0903 - acc: 0.9865\n",
      "Epoch 588/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.1114 - acc: 0.9730\n",
      "Epoch 589/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.1292 - acc: 0.9550\n",
      "Epoch 590/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.1147 - acc: 0.9640\n",
      "Epoch 591/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.1343 - acc: 0.9595\n",
      "Epoch 592/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.1073 - acc: 0.9685\n",
      "Epoch 593/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.1413 - acc: 0.9505\n",
      "Epoch 594/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.0738 - acc: 0.9820\n",
      "Epoch 595/700\n",
      "222/222 [==============================] - 0s 116us/step - loss: 0.0967 - acc: 0.9730\n",
      "Epoch 596/700\n",
      "222/222 [==============================] - 0s 105us/step - loss: 0.0886 - acc: 0.9865\n",
      "Epoch 597/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.0891 - acc: 0.9730\n",
      "Epoch 598/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.1301 - acc: 0.9685\n",
      "Epoch 599/700\n",
      "222/222 [==============================] - 0s 115us/step - loss: 0.0708 - acc: 0.9820\n",
      "Epoch 600/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.0963 - acc: 0.9820\n",
      "Epoch 601/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.0818 - acc: 0.9820\n",
      "Epoch 602/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.0826 - acc: 0.9775\n",
      "Epoch 603/700\n",
      "222/222 [==============================] - 0s 117us/step - loss: 0.1270 - acc: 0.9595\n",
      "Epoch 604/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.1049 - acc: 0.9685\n",
      "Epoch 605/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.1287 - acc: 0.9595\n",
      "Epoch 606/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.1115 - acc: 0.9685\n",
      "Epoch 607/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.0803 - acc: 0.9775\n",
      "Epoch 608/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.1053 - acc: 0.9640\n",
      "Epoch 609/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.0981 - acc: 0.9820\n",
      "Epoch 610/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.1099 - acc: 0.9775\n",
      "Epoch 611/700\n",
      "222/222 [==============================] - 0s 116us/step - loss: 0.1121 - acc: 0.9595\n",
      "Epoch 612/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.1210 - acc: 0.9595\n",
      "Epoch 613/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.0885 - acc: 0.9775\n",
      "Epoch 614/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.1087 - acc: 0.9640\n",
      "Epoch 615/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.0528 - acc: 0.9865\n",
      "Epoch 616/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.1147 - acc: 0.9640\n",
      "Epoch 617/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.0550 - acc: 0.9775\n",
      "Epoch 618/700\n",
      "222/222 [==============================] - 0s 119us/step - loss: 0.0895 - acc: 0.9730\n",
      "Epoch 619/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.0904 - acc: 0.9730\n",
      "Epoch 620/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.0285 - acc: 0.9955\n",
      "Epoch 621/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.0940 - acc: 0.9730\n",
      "Epoch 622/700\n",
      "222/222 [==============================] - 0s 102us/step - loss: 0.1104 - acc: 0.9775\n",
      "Epoch 623/700\n",
      "222/222 [==============================] - 0s 104us/step - loss: 0.0717 - acc: 0.9775\n",
      "Epoch 624/700\n",
      "222/222 [==============================] - 0s 101us/step - loss: 0.1133 - acc: 0.9685\n",
      "Epoch 625/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.0894 - acc: 0.9775\n",
      "Epoch 626/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.0556 - acc: 1.0000\n",
      "Epoch 627/700\n",
      "222/222 [==============================] - 0s 115us/step - loss: 0.1234 - acc: 0.9640\n",
      "Epoch 628/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.1140 - acc: 0.9640\n",
      "Epoch 629/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.0977 - acc: 0.9730\n",
      "Epoch 630/700\n",
      "222/222 [==============================] - 0s 100us/step - loss: 0.0984 - acc: 0.9685\n",
      "Epoch 631/700\n",
      "222/222 [==============================] - 0s 100us/step - loss: 0.0763 - acc: 0.9910\n",
      "Epoch 632/700\n",
      "222/222 [==============================] - 0s 101us/step - loss: 0.1117 - acc: 0.9775\n",
      "Epoch 633/700\n",
      "222/222 [==============================] - 0s 97us/step - loss: 0.1201 - acc: 0.9685\n",
      "Epoch 634/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.0996 - acc: 0.9730\n",
      "Epoch 635/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.1329 - acc: 0.9595\n",
      "Epoch 636/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.0646 - acc: 0.9910\n",
      "Epoch 637/700\n",
      "222/222 [==============================] - 0s 104us/step - loss: 0.0973 - acc: 0.9775\n",
      "Epoch 638/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.1092 - acc: 0.9640\n",
      "Epoch 639/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.0767 - acc: 0.9775\n",
      "Epoch 640/700\n",
      "222/222 [==============================] - 0s 104us/step - loss: 0.0978 - acc: 0.9820\n",
      "Epoch 641/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.0501 - acc: 0.9820\n",
      "Epoch 642/700\n",
      "222/222 [==============================] - 0s 115us/step - loss: 0.0537 - acc: 0.9865\n",
      "Epoch 643/700\n",
      "222/222 [==============================] - 0s 115us/step - loss: 0.1159 - acc: 0.9595\n",
      "Epoch 644/700\n",
      "222/222 [==============================] - 0s 126us/step - loss: 0.1415 - acc: 0.9414\n",
      "Epoch 645/700\n",
      "222/222 [==============================] - 0s 119us/step - loss: 0.1716 - acc: 0.9505\n",
      "Epoch 646/700\n",
      "222/222 [==============================] - 0s 103us/step - loss: 0.0703 - acc: 0.9865\n",
      "Epoch 647/700\n",
      "222/222 [==============================] - 0s 104us/step - loss: 0.0951 - acc: 0.9775\n",
      "Epoch 648/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.0474 - acc: 0.9955\n",
      "Epoch 649/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222/222 [==============================] - 0s 107us/step - loss: 0.0783 - acc: 0.9775\n",
      "Epoch 650/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.0978 - acc: 0.9820\n",
      "Epoch 651/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 0.0227 - acc: 1.0000\n",
      "Epoch 652/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.1658 - acc: 0.9505\n",
      "Epoch 653/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.1383 - acc: 0.9640\n",
      "Epoch 654/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 0.0649 - acc: 0.9820\n",
      "Epoch 655/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.0753 - acc: 0.9865\n",
      "Epoch 656/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.0664 - acc: 0.9820\n",
      "Epoch 657/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.0916 - acc: 0.9685\n",
      "Epoch 658/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.1630 - acc: 0.9505\n",
      "Epoch 659/700\n",
      "222/222 [==============================] - 0s 119us/step - loss: 0.0922 - acc: 0.9730\n",
      "Epoch 660/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.0282 - acc: 0.9955\n",
      "Epoch 661/700\n",
      "222/222 [==============================] - 0s 122us/step - loss: 0.0697 - acc: 0.9910\n",
      "Epoch 662/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.1000 - acc: 0.9685\n",
      "Epoch 663/700\n",
      "222/222 [==============================] - 0s 117us/step - loss: 0.0475 - acc: 0.9910\n",
      "Epoch 664/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.0726 - acc: 0.9775\n",
      "Epoch 665/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.0547 - acc: 0.9910\n",
      "Epoch 666/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.0749 - acc: 0.9775\n",
      "Epoch 667/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 0.1287 - acc: 0.9730\n",
      "Epoch 668/700\n",
      "222/222 [==============================] - 0s 116us/step - loss: 0.0602 - acc: 0.9910\n",
      "Epoch 669/700\n",
      "222/222 [==============================] - 0s 104us/step - loss: 0.0497 - acc: 0.9910\n",
      "Epoch 670/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.1214 - acc: 0.9550\n",
      "Epoch 671/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.0836 - acc: 0.9865\n",
      "Epoch 672/700\n",
      "222/222 [==============================] - 0s 112us/step - loss: 0.0779 - acc: 0.9730\n",
      "Epoch 673/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.0739 - acc: 0.9865\n",
      "Epoch 674/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.0423 - acc: 0.9865\n",
      "Epoch 675/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.0559 - acc: 0.9910\n",
      "Epoch 676/700\n",
      "222/222 [==============================] - 0s 113us/step - loss: 0.1062 - acc: 0.9775\n",
      "Epoch 677/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.1051 - acc: 0.9640\n",
      "Epoch 678/700\n",
      "222/222 [==============================] - 0s 119us/step - loss: 0.1024 - acc: 0.9685\n",
      "Epoch 679/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.0633 - acc: 0.9910\n",
      "Epoch 680/700\n",
      "222/222 [==============================] - 0s 119us/step - loss: 0.0763 - acc: 0.9775\n",
      "Epoch 681/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.1004 - acc: 0.9685\n",
      "Epoch 682/700\n",
      "222/222 [==============================] - 0s 123us/step - loss: 0.0630 - acc: 0.9820\n",
      "Epoch 683/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 0.1042 - acc: 0.9685\n",
      "Epoch 684/700\n",
      "222/222 [==============================] - 0s 99us/step - loss: 0.1013 - acc: 0.9775\n",
      "Epoch 685/700\n",
      "222/222 [==============================] - 0s 110us/step - loss: 0.0964 - acc: 0.9730\n",
      "Epoch 686/700\n",
      "222/222 [==============================] - 0s 106us/step - loss: 0.0943 - acc: 0.9730\n",
      "Epoch 687/700\n",
      "222/222 [==============================] - 0s 103us/step - loss: 0.0593 - acc: 0.9865\n",
      "Epoch 688/700\n",
      "222/222 [==============================] - 0s 115us/step - loss: 0.0426 - acc: 0.9955\n",
      "Epoch 689/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.0899 - acc: 0.9775\n",
      "Epoch 690/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.0884 - acc: 0.9775\n",
      "Epoch 691/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.0778 - acc: 0.9820\n",
      "Epoch 692/700\n",
      "222/222 [==============================] - 0s 111us/step - loss: 0.1014 - acc: 0.9685\n",
      "Epoch 693/700\n",
      "222/222 [==============================] - 0s 109us/step - loss: 0.0942 - acc: 0.9775\n",
      "Epoch 694/700\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.0866 - acc: 0.9775\n",
      "Epoch 695/700\n",
      "222/222 [==============================] - 0s 117us/step - loss: 0.1612 - acc: 0.9414\n",
      "Epoch 696/700\n",
      "222/222 [==============================] - 0s 121us/step - loss: 0.0966 - acc: 0.9730\n",
      "Epoch 697/700\n",
      "222/222 [==============================] - 0s 114us/step - loss: 0.0917 - acc: 0.9775\n",
      "Epoch 698/700\n",
      "222/222 [==============================] - 0s 107us/step - loss: 0.1234 - acc: 0.9640\n",
      "Epoch 699/700\n",
      "222/222 [==============================] - 0s 100us/step - loss: 0.1576 - acc: 0.9595\n",
      "Epoch 700/700\n",
      "222/222 [==============================] - 0s 105us/step - loss: 0.0982 - acc: 0.9730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_core.policies.keras_policy:Done fitting keras policy model\n",
      "Processed actions: 222it [00:00, 1588.17it/s, # examples=222]\n",
      "INFO:rasa_core.agent:Model directory models/dialogue exists and contains old model files. All files will be overwritten.\n",
      "INFO:rasa_core.agent:Persisted model to '/Users/saching12/Desktop/python codes/student_assistant_chatbot/models/dialogue'\n"
     ]
    }
   ],
   "source": [
    "from rasa_core.policies import FallbackPolicy, KerasPolicy, MemoizationPolicy\n",
    "from rasa_core.agent import Agent\n",
    "from rasa_core import config\n",
    "\n",
    "\n",
    "agent = Agent('domain.yml', policies=config.load('policy_config.yml'))\n",
    "\n",
    "# loading our neatly defined training dialogues\n",
    "training_data = agent.load_data('stories.md')\n",
    "\n",
    "agent.train(training_data)\n",
    "\n",
    "agent.persist('models/dialogue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4911z6y-5rD",
    "pycharm": {}
   },
   "source": [
    "# Talk to your Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nE4coPam5hry",
    "outputId": "c8ec135b-882b-4e9e-a955-f3e184177817",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:rasa_core.agent:Passing a value for interpreter to an agent where the value is not an interpreter is deprecated. Construct the interpreter, beforepassing it to the agent, e.g. `interpreter = NaturalLanguageInterpreter.create(nlu)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/saching12/Desktop/python codes/student_assistant_chatbot/./models/nlu/default/current/intent_classifier_tensorflow_embedding.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/saching12/Desktop/python codes/student_assistant_chatbot/./models/nlu/default/current/intent_classifier_tensorflow_embedding.ckpt\n"
     ]
    }
   ],
   "source": [
    "#Starting the Bot\n",
    "\n",
    "from rasa_core.agent import Agent\n",
    "agent = Agent.load('models/dialogue', interpreter=model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "DDVLzhAT5yrP",
    "outputId": "aee3fc83-df97-42b4-c7e0-c8929f76337c",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your bot is ready to talk! Type your messages here or send 'stop'\n",
      "is there any event tomorrow?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:rasa_core.processor:Encountered an exception while running action 'action_retrieve_event'. Bot will continue, but the actions events are lost. Make sure to fix the exception in your custom code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did that help you?\n"
     ]
    }
   ],
   "source": [
    "print(\"Your bot is ready to talk! Type your messages here or send 'stop'\")\n",
    "while True:\n",
    "    a = input()\n",
    "    if a == 'stop':\n",
    "        break\n",
    "    responses = agent.handle_text(a)\n",
    "    for response in responses:\n",
    "        print(response[\"text\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "enJNkbvB54y1",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Conversational_Chatbot.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
